{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch05/01_main-chapter-code/ch05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45398736-7e89-4263-89c8-92153baff553",
      "metadata": {
        "id": "45398736-7e89-4263-89c8-92153baff553"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
        "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
      "metadata": {
        "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
      },
      "source": [
        "# 5장: 레이블이 없는 데이터를 활용한 사전 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "92b989e9-da36-4159-b212-799184764dd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b989e9-da36-4159-b212-799184764dd9",
        "outputId": "3cd7e224-7b3b-46e3-9df3-ffb61fc344c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matplotlib 버전: 3.10.6\n",
            "numpy 버전: 1.26.4\n",
            "tiktoken 버전: 0.12.0\n",
            "torch 버전: 2.5.1\n",
            "tensorflow 버전: 2.19.1\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\" # OpenAI의 사전 훈련된 가중치를 위해서\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} 버전: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
      "metadata": {
        "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237"
      },
      "source": [
        "- 이 장에서 LLM을 사전 훈련하기 위해 훈련 루프를 구현하고 기본적인 모델 평가 방법을 알아 보겠습니다.\n",
        "- 이 장의 끝에서는 OpenAI의 사전 훈련된 가중치를 우리가 직접 구현한 모델에 로드해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
      "metadata": {
        "id": "efd27fcc-2886-47cb-b544-046c2c31f02a"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/01.webp\" width=800px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d214765-7a73-42d5-95e9-302154b29db9",
      "metadata": {
        "id": "0d214765-7a73-42d5-95e9-302154b29db9"
      },
      "source": [
        "- 이 장에서 다루는 주제는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
      "metadata": {
        "id": "f67711d4-8391-4fee-aeef-07ea53dd5841"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/02.webp\" width=800px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
      "metadata": {
        "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
      },
      "source": [
        "## 5.1 텍스트 생성 모델 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
      "metadata": {
        "id": "a3350f8c-5181-4f9b-a789-4523105e98f2"
      },
      "source": [
        "- 이전 장에 코드를 사용하여 GPT 모델을 초기화하는 방법을 간략히 정리합니다.\n",
        "- 그다음 LLM을 위한 기본적인 평가 지표를 소개합니다.\n",
        "- 이 절의 마지막에서 이 평가 지표를 훈련 세트와 검증 세트에 적용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
      "metadata": {
        "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
      },
      "source": [
        "### 5.1.1 GPT를 사용해 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
      "metadata": {
        "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc"
      },
      "source": [
        "- 이전 장의 코드를 사용하여 GPT 모델을 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "oujnEbGCRVJe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oujnEbGCRVJe",
        "outputId": "ed9fa722-71d2-4467-dcd8-4aa5cb5ad47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "# 깃허브에서 previous_chapters.py 파일을 다운로드합니다.\n",
        "!wget https://bit.ly/3HlFmc8 -O previous_chapters.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "86000d74-624a-48f0-86da-f41926cb9e04",
      "metadata": {
        "id": "86000d74-624a-48f0-86da-f41926cb9e04"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from gpt_module import GPTModel\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # 어휘 사전 크기\n",
        "    \"context_length\": 256, # 짧은 문맥 길이 (원본 길이: 1024)\n",
        "    \"emb_dim\": 768,        # 임베딩 차원\n",
        "    \"n_heads\": 12,         # 어텐션 헤드 개수\n",
        "    \"n_layers\": 12,        # 층 개수\n",
        "    \"drop_rate\": 0.1,      # 드롭아웃 비율\n",
        "    \"qkv_bias\": False      # 쿼리-키-값 생성시 편향 사용 여부\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();  # 추론 시에는 드롭아웃을 비활성화합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
      "metadata": {
        "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c"
      },
      "source": [
        "- 위에서 드롭아웃을 0.1로 지정했지만 요즘에는 드롭아웃을 사용하지 않고 LLM을 훈련하는 경우가 많습니다.\n",
        "- 최신 LLM은 (초기 GPT 모델과 달리) 쿼리, 키, 값 행렬을 위한 `nn.Linear` 층에서 편향 벡터를 사용하지 않습니다. 그래서 `\"qkv_bias\": False`로 지정합니다.\n",
        "- 모델 훈련에 필요한 계산 자원을 절감하기 위해 문맥 길이(`context_length`)를 256 토큰으로 줄입니다. 원본 1억 2,400만 파라미터의 GPT-2 모델은 1024개의 토큰을 사용했습니다.\n",
        "  - 대부분의 독자들은 이 코드 예제를 랩탑 컴퓨터에서 실행하기 때문입니다.\n",
        "  - 하지만 `context_length`를 1,024개 토큰으로 늘려서 실험해도 괜찮습니다(어떤 코드도 바꿀 필요가 없습니다)\n",
        "  - 나중에 `context_length`가 1,024인 모델을 사전 훈련된 가중치에서 로드하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
      "metadata": {
        "id": "59f80895-be35-4bb5-81cb-f357ef7367fe"
      },
      "source": [
        "- 그 다음이 이전 장에서 만든 `generate_text_simple` 함수를 사용해 텍스트를 생성합니다.\n",
        "- 또한 두 개 유틸리티 함수 `text_to_token_ids`와 `token_ids_to_text`를 정의합니다. 이 장에서 토큰과 텍스트 표현 사이를 전환하는데 사용하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
      "metadata": {
        "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/03.webp\" width=900px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
        "outputId": "5279ae1f-51e9-4792-9d4d-a9233628df8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "출력 텍스트:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "from gpt_module import generate_text_simple\n",
        "\n",
        "# 텍스트 -> 토큰 id로 변환\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 배치 차원을 추가합니다.\n",
        "    return encoded_tensor\n",
        "\n",
        "# 토큰 id -> 텍스트로 변환\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # 배치 차원을 삭제합니다\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# gpt2모델 실행\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
      "metadata": {
        "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305"
      },
      "source": [
        "- 위해서 볼 수 있듯이 모델이 아직 훈련되지 않았기 때문에 좋은 텍스트를 생성하지 못합니다.\n",
        "- 훈련 과정에서 어떤 것이 좋은 텍스트인지 어떻게 정량적으로 측정할 수 있을까요?\n",
        "- 다음 절에서 훈련 과정을 모니터링할 수 있도록 생성된 출력의 손실을 계산하는 지표를 소개합니다.\n",
        "- LLM 미세 튜닝을 다루는 다음 장에서 모델의 품질을 측정하는 또 다른 방법을 소개하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
      "metadata": {
        "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
      },
      "source": [
        "### 5.1.2 텍스트 생성 손실 계산하기: 크로스 엔트로피와 혼잡도"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
      "metadata": {
        "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440"
      },
      "source": [
        "- 두 개의 훈련 샘플(행)에 대한 토큰 ID를 담고 있는 `inputs` 텐서가 있다고 가정해보죠.\n",
        "- `inputs`에 해당하는 `targets`은 모델이 생성 해야할 토큰 ID를 담고 있습니다.\n",
        "- 2장에서 데이터 로더를 구현할 때 설명했듯이 `targets`은 `inputs`에서 한 토큰씩 앞으로 이동한 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
      "metadata": {
        "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
      "metadata": {
        "id": "33dc0645-ac2c-4973-9b40-6da40515bede"
      },
      "source": [
        "- `inputs`을 모델에 주입하면 각각 세 개의 토큰으로 구성된 두 개의 입력 샘플에 대한 로짓 벡터를 얻습니다.\n",
        "- 각각의 토큰는 어휘 사전 크기에 해당하는 50,257차원의 벡터입니다.\n",
        "- 소프트맥스 함수를 적용하여 로짓 텐서을 확률 점수를 담고 있는 동일 차원의 텐서로 바꿀 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
        "outputId": "33d943d3-43f8-4d96-fee7-bdf4e7d2b3b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1) # 어휘 사전의 각 토큰에 대한 확률\n",
        "print(probas.shape) # 크기: (batch_size, num_tokens, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
      "metadata": {
        "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b"
      },
      "source": [
        "- 매우 작은 어휘 사전을 사용하는 아래 그림에서 확률 점수를 텍스트로 바꾸는 방법을 보여 줍니다. 이 장의 끝에서 이에 대해 논의하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
      "metadata": {
        "id": "384d86a9-0013-476c-bb6b-274fd5f20b29"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/04.webp\" width=900px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8480efd-d419-4954-9ecc-2876055334bd",
      "metadata": {
        "id": "e8480efd-d419-4954-9ecc-2876055334bd"
      },
      "source": [
        "- 이전 장에서 설명했듯이 `argmax` 함수를 적용하여 확률 점수를 토큰 ID 바꿀 수 있습니다.\n",
        "- 앞의 소프트맥스 함수는 각 토큰에 대해서 50,257 차원의 벡터를 생성합니다. `argmax` 함수는 이 벡터에서 가장 높은 확률을 가진 위치를 반환합니다. 이것이 주어진 토큰에 대한 예측 토큰의 아이디입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
      "metadata": {
        "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144"
      },
      "source": [
        "- 배치에는 각각 세 개 토큰으로 구성된 두 개의 입력 샘플이 있으므로 2x3 크기의 예측 토큰을 얻습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
        "outputId": "3b012f1f-3487-4e2b-ef67-13ec2388ca9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "토큰 ID:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ],
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"토큰 ID:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee4072c-21ed-4df7-8721-dd2535362573",
      "metadata": {
        "id": "cee4072c-21ed-4df7-8721-dd2535362573"
      },
      "source": [
        "- 이 토큰을 디코딩하면 모델이 예측해야 할 토큰, 즉 타겟 토큰과 매우 다른 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
        "outputId": "a8b2234e-fe6e-4160-bf94-5d6c670732b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "첫 번째 샘플의 타깃:  effort moves you\n",
            "첫 번째 샘플의 타깃:  Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"첫 번째 샘플의 타깃: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
      "metadata": {
        "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2"
      },
      "source": [
        "- 이는 모델이 아직 훈련되지 않았기 때문입니다.\n",
        "- 모델을 훈련하려면 정답 예측(타깃)에서 얼만큼 떨어져 있는지 알아야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
      "metadata": {
        "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/06.webp\" width=900px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7251bf5-a079-4782-901d-68c9225d3157",
      "metadata": {
        "id": "c7251bf5-a079-4782-901d-68c9225d3157"
      },
      "source": [
        "- 타겟 인덱스에 해당하는 토큰 확률은 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
        "outputId": "3127e9fc-0474-4477-970a-e26772e7e4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "텍스트 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
            "텍스트 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] # [2, 3, 50257]\n",
        "print(\"텍스트 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"텍스트 2:\", target_probas_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
      "metadata": {
        "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf"
      },
      "source": [
        "- 확률이 1에 가까워지도록 이 값들을 최대화하는 것이 목표입니다.\n",
        "- 수학적 최적화에서는 확률 점수 자체를 최대화하는 것보다 확률 점수의 로그를 최대화하는 것이 쉽습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
        "outputId": "4d156f96-b2b7-438f-9827-8f5a396b4738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
          ]
        }
      ],
      "source": [
        "# 토큰 확률의 로그를 계산합니다.\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4261441-a511-4633-9c4c-67998af31b84",
      "metadata": {
        "id": "c4261441-a511-4633-9c4c-67998af31b84"
      },
      "source": [
        "- 그 다음 로그 확률의 평균을 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9b003797-161b-4d98-81dc-e68320e09fec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b003797-161b-4d98-81dc-e68320e09fec",
        "outputId": "d0f5bde2-7403-4bf3-92e2-4ab4b8e7fb6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-10.7940)\n"
          ]
        }
      ],
      "source": [
        "# 각 토큰에 대한 평균 확률을 계산합니다.\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
      "metadata": {
        "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585"
      },
      "source": [
        "- 모델 가중치를 최적화하여 평균 로그 확률을 가능한 크게 만드는 것이 목표입니다.\n",
        "- 로그 때문에 가장 큰 가능한 값은 0이며, 현재는 0에서 부터 멀리 떨어져 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
      "metadata": {
        "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514"
      },
      "source": [
        "- 딥러닝 에서는 평균 로그 확률을 최대화하는 것 대신에 음의 평균 로그 확률을 최소화하는 것이 일반적입니다. 이 예제의 경우 -10.7722를 최대화하여 0에 가깝게 만드는 것 대신에 10.7722을 최소화하여 0에 가깝게 만듭니다.\n",
        "- -10.7722의 음수 값, 즉 10.7722을 딥러닝에서는 크로스 엔트로피 손실이라고 부릅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
        "outputId": "6cb796d8-26e3-4de7-f46e-5ba0d2c5fd09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
      "metadata": {
        "id": "84eeb868-abd8-4028-82db-107546bf7c2c"
      },
      "source": [
        "- 파이토치는 이전 단계를 수행하는 `cross_entropy` 함수를 제공합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
      "metadata": {
        "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/07.webp\" width=600px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
      "metadata": {
        "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d"
      },
      "source": [
        "1. `cross_entropy` 함수를 적용하기 전에 로짓과 타깃의 크기를 확인해야 합니다.\n",
        "2.  파이토치의 `cross_entropy` 함수를 위해 배치 차원을 기준으로 합쳐서 텐서를 펼쳐야 합니다.\n",
        "3.  타깃은 토큰 ID이며, 최대화해야 할 로짓 텐서의 인덱스를 나타냅니다.\n",
        "    - 파이토치의 `cross_entropy` 함수는 최대화할 토큰 인덱스에 대해 자동으로 소프트맥스와 로그 확률 계산을 수행합니다.\n",
        "\n",
        "4. 크로스 엔트로피 손실에 관련된 개념은 LLM의 혼잡도입니다.\n",
        "    - 혼잡도는 크로스 엔트로피 손실에 지수 함수를 적용한 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
        "outputId": "760d5805-9184-4169-a4a3-793c9be5993e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "로짓 크기: torch.Size([2, 3, 50257])\n",
            "타깃 크기: torch.Size([2, 3])\n",
            "펼친 로짓: torch.Size([6, 50257])\n",
            "펼친 타깃: torch.Size([6])\n",
            "tensor(10.7940)\n",
            "tensor(48725.8203)\n"
          ]
        }
      ],
      "source": [
        "## 1. \n",
        "# 로짓의 크기는 (batch_size, num_tokens, vocab_size)입니다.\n",
        "print(\"로짓 크기:\", logits.shape)\n",
        "\n",
        "# 타깃의 크기는 (batch_size, num_tokens)입니다.\n",
        "print(\"타깃 크기:\", targets.shape)\n",
        "\n",
        "\n",
        "## 2. \n",
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"펼친 로짓:\", logits_flat.shape)\n",
        "print(\"펼친 타깃:\", targets_flat.shape)\n",
        "\n",
        "## 3. \n",
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)\n",
        "\n",
        "## 4. \n",
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
      "metadata": {
        "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7"
      },
      "source": [
        "- 혼잡도는 모델이 각 단계에서 불확실해하는 실제 어휘사전 크기를 나타내기 때문에 원시 손실 값보다 이해하기 더 쉽습니다(이 예에서는 48,725개 단어 또는 토큰).\n",
        "- 다른 말로 하면, 혼잡도는 모델이 예측한 확률 분포가 데이터셋에 있는 단어의 실제 분포와 얼마나 잘 맞는지를 측정합니다.\n",
        "- 손실과 비슷하게 낮은 혼잡도는 모델 예측이 실제 분포에 가깝다는 것을 나타냅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
      "metadata": {
        "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
      },
      "source": [
        "### 5.1.3 훈련 세트와 검증 세트의 손실 계산하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
      "metadata": {
        "id": "530da89e-2448-436c-8f1b-28e8a31ef85c"
      },
      "source": [
        "- LLM 훈련을 위해 비교적 작은 데이터셋을 사용합니다(사실 단편 소설 하나를 사용합니다).\n",
        "- 이유는 다음과 같습니다.\n",
        "  - 적절한 GPU가 없는 랩탑 컴퓨터에서 몇 분 안에 코드 예제가 실행되어야 합니다.\n",
        "  - 교육 목적을 위해 훈련이 비교적 빨리 끝나야 합니다(몇 주가 아니라 몇 분 만에).\n",
        "  - 사용 권리를 위반하지 않으며 깃허브 저장소에 저장할 수 있는 크기의 공개된 텍스트를 사용해야 합니다.\n",
        "- 예를 들어, Llama 2 7B는 2조 개의 토큰에서 훈련하기 위해 A100 GPU에서 184,320 GPU 시간이 필요합니다.\n",
        "  - 이 글을 쓰는 시점에, AWS의 8xA100 클라우드 서버의 시간당 가격은 약 \\$30입니다.\n",
        "  - 따라서 대략 계산하면 이 LLM을 훈련하는데 184,320 / 8 * \\$30 =  \\$690,000이 듭니다.\n",
        "- 아래에서는 2장에서 다루었던 데이터셋을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
      "metadata": {
        "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "file_path = \"the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    response = requests.get(url, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    text_data = response.text\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()\n",
        "\n",
        "# 책에서는 다음 코드를 사용했지만 VPN을 사용하는 경우 urllib가 문제를 일으킬 수 있습니다.\n",
        "# 따라서 더 안정적인 `requests` 패키지를 사용합니다.\n",
        "\n",
        "# import os\n",
        "# import urllib.request\n",
        "\n",
        "# file_path = \"the-verdict.txt\"\n",
        "# url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "# if not os.path.exists(file_path):\n",
        "#     with urllib.request.urlopen(url) as response:\n",
        "#         text_data = response.read().decode('utf-8')\n",
        "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "#         file.write(text_data)\n",
        "# else:\n",
        "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "#         text_data = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "379330f1-80f4-4e34-8724-41d892b04cee",
      "metadata": {
        "id": "379330f1-80f4-4e34-8724-41d892b04cee"
      },
      "source": [
        "- 다운로드한 텍스트를 확인하기 위해 처음과 끝에서 100 개의 문자를 출력하여 보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "6kgJbe4ehI4q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kgJbe4ehI4q",
        "outputId": "0cadf8fb-eb0f-4f1b-f962-24d54e4c69ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "# 처음 99개 문자\n",
        "print(text_data[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "j2XPde_ThM_e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2XPde_ThM_e",
        "outputId": "303f89a2-b40f-4f2f-cf75-537b2d4947ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
          ]
        }
      ],
      "source": [
        "# 마지막 99개 문자\n",
        "print(text_data[-99:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
        "outputId": "9905e789-a021-4ffa-bf94-30ee0752a9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문자: 20479\n",
            "토큰: 5145\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(\"문자:\", total_characters)\n",
        "print(\"토큰:\", total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
      "metadata": {
        "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7"
      },
      "source": [
        "이 텍스트의 토큰이 5,145개 뿐이라 LLM을 훈련하기에 너무 적어 보일 수 있습니다. 하지만 이는 교육적인 목적을 위해서입니다(나중에 사전 훈련된 가중치를 로드하겠습니다)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
      "metadata": {
        "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f"
      },
      "source": [
        "- 그 다음 데이터셋을 훈련 세트와 검증 세트로 나누고 2장의 데이터 로더를 사용해 LLM 훈련을 위한 배치를 준비합니다.\n",
        "- 시각화때문에 아래 그림은 `max_length=6`라고 가정하지만, 훈련 데이터 로더에서 `max_length`는 LLM이 지원하는 문맥 길이와 같습니다.\n",
        "- 아래 그림은 간단하게 나타내려고 입력 토큰만 보여줍니다.\n",
        "  - LLM을 텍스트에 있는 다음 단어를 예측하도록 훈련하기 때문에 타깃은 한 토큰씩 이동한 것외에는 입력과 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
      "metadata": {
        "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/09.webp\" width=900px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "0959c855-f860-4358-8b98-bc654f047578",
      "metadata": {
        "id": "0959c855-f860-4358-8b98-bc654f047578"
      },
      "outputs": [],
      "source": [
        "from gpt_module import create_dataloader_v1\n",
        "\n",
        "# 훈련 세트 비율\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
      "metadata": {
        "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e"
      },
      "outputs": [],
      "source": [
        "# 유효성 검사\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
        "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
        "          \"`training_ratio`를 증가시키세요.\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"훈련 데이터 로더에 토큰이 충분하지 않습니다. \"\n",
        "          \"`GPT_CONFIG_124M['context_length']`를 낮추거나 \"\n",
        "          \"`training_ratio`를 증가시키세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
      "metadata": {
        "id": "e7ac3296-a4d1-4303-9ac5-376518960c33"
      },
      "source": [
        "- 컴퓨팅 자원을 절감하고 데이터셋이 매우 작기 때문에 비교적 작은 배치 크기를 사용합니다.\n",
        "- 예를 들어 Llama 2 7B는 배치 크기 1024에서 훈련되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
      "metadata": {
        "id": "a8e0514d-b990-4dc0-9afb-7721993284a0"
      },
      "source": [
        "- 데이터가 올바르게 로드되었는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
        "outputId": "a65d09ed-241c-4361-cc5c-4fd0beb847ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련 데이터 로더:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "검증 데이터 로더:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "print(\"훈련 데이터 로더:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\n검증 데이터 로더:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
      "metadata": {
        "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed"
      },
      "source": [
        "- 토큰 크기가 예상 범위 안에 있는지 추가로 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "eb860488-5453-41d7-9870-23b723f742a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb860488-5453-41d7-9870-23b723f742a0",
        "outputId": "92779d81-f4ad-488e-c4d1-ffcd7e113f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련 토큰 수: 4608\n",
            "검증 토큰 수: 512\n",
            "모든 토큰 수: 5120\n"
          ]
        }
      ],
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"훈련 토큰 수:\", train_tokens)\n",
        "print(\"검증 토큰 수:\", val_tokens)\n",
        "print(\"모든 토큰 수:\", train_tokens + val_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
      "metadata": {
        "id": "5c3085e8-665e-48eb-bb41-cdde61537e06"
      },
      "source": [
        "- 주어진 배치에서 크로스 엔트로피 손실을 계산 하는 유틸리티 함수를 작성 합니다\n",
        "- 또한 데이터 로더에서 사용자가 지정한 배치 개수 만큼 추출하여 손실을 계산하는 두 번째 유틸리티 함수를 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
      "metadata": {
        "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
      },
      "outputs": [],
      "source": [
        "# 배치 한개씩 손실을 계산하는 함수\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "# 여러개의 배치의 손실을 합쳐서 계산하는 함수\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # num_batches가 데이터 로더에 있는 배치 개수보다 크면\n",
        "        # 배치 횟수를 데이터 로더에 있는 총 배치 개수로 맞춥니다.\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
      "metadata": {
        "id": "f0691332-84d0-48b3-b462-a885ddeb4fca"
      },
      "source": [
        "- CUDA를 지원하는 GPU를 가지고 있다면 어떤 코드도 변경할 필요 없이 GPU 에서 LLM을 훈련할 수 있습니다.\n",
        "- `device` 설정을 통해 데이터를 LLM 모델과 동일한 장치에 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
        "outputId": "92b1c926-bb46-4029-c371-116a52dba18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련 손실: 5.179231325785319\n",
            "검증 손실: 6.347812652587891\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
        "\n",
        "# 노트:\n",
        "# 애플 실리콘 칩에서 코드를 실행하는 경우 다음 주석을 해제하세요.\n",
        "# (M3 맥북 에어에서 측정하면) 애플 CPU보다 약 2배 빠릅니다. 하지만 손실 값은 조금 다를 수 있습니다.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#\n",
        "# print(f\"Using {device} device.\")\n",
        "\n",
        "\n",
        "model.to(device) # nn.Module 클래스의 경우 model = model.to(device)로 할당할 필요가 없습니다.\n",
        "\n",
        "torch.manual_seed(123) # 데이터 로더에서 셔플링이 일어나므로 재현가능성을 위해 설정합니다.\n",
        "\n",
        "with torch.no_grad(): # 모델을 아직 훈련하지 않으므로 효율성을 위해 그레이디언트 추적을 끕니다.\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"훈련 손실:\", train_loss)\n",
        "print(\"검증 손실:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
      "metadata": {
        "id": "43875e95-190f-4b17-8f9a-35034ba649ec"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/10.webp\" width=800px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
      "metadata": {
        "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
      },
      "source": [
        "## 5.2 LLM 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
      "metadata": {
        "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd"
      },
      "source": [
        "- 이 절에서는 LLM 훈련을 위한 코드를 구현합니다.\n",
        "- 여기서는 간단한 훈련 함수를 만듭니다(이 훈련 함수를 학습률 워밍업, 코사인 어닐링, 그레이디언트 클리핑 같은 고급 기법으로 확장하고 싶다면 [부록 D](../../appendix-D/01_main-chapter-code)를 참고하세요).\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/11.webp\" width=600px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "Mtp4gY0ZO-qq",
      "metadata": {
        "id": "Mtp4gY0ZO-qq"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # 손실과 지금까지 처리한 토큰 수를 추적하기 위해 리스트를 초기화합니다.\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # 메인 훈련 루프를 시작합니다.\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # 모델을 훈련 모드로 설정합니다.\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # 이전 배치 반복에서 얻은 손실의 그레이디언트를 초기화합니다.\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # 손실의 그레이디언트를 계산합니다.\n",
        "            optimizer.step() # 손실의 그레이디언트를 사용하여 모델 가중치를 업데이트합니다.\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # 추가적인 평가 단계\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
        "\n",
        "        # 각 에포크 후에 샘플 텍스트를 출력합니다.\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # 간결한 출력 포맷을 위해\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
      "metadata": {
        "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47"
      },
      "source": [
        "- 위에 정의한 훈련 함수로 LLM을 훈련해 보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "3422000b-7aa2-485b-92df-99372cd22311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3422000b-7aa2-485b-92df-99372cd22311",
        "outputId": "a26c122c-a492-49fd-aefc-9ecf0ef044b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "에포크 1 (Step 000000): 훈련 손실 10.973, 검증 손실 10.985\n",
            "에포크 1 (Step 000005): 훈련 손실 9.639, 검증 손실 9.768\n",
            "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "에포크 2 (Step 000010): 훈련 손실 8.412, 검증 손실 8.663\n",
            "에포크 2 (Step 000015): 훈련 손실 7.348, 검증 손실 7.656\n",
            "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "에포크 3 (Step 000020): 훈련 손실 6.500, 검증 손실 6.898\n",
            "에포크 3 (Step 000025): 훈련 손실 6.101, 검증 손실 6.639\n",
            "Every effort moves you the... the the. the the the.. the.. the the the the the. the the.. the. the. the the. the the the the. the. the. the the. the the. the. the\n",
            "에포크 4 (Step 000030): 훈련 손실 6.015, 검증 손실 6.624\n",
            "에포크 4 (Step 000035): 훈련 손실 6.012, 검증 손실 6.676\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "에포크 5 (Step 000040): 훈련 손실 5.946, 검증 손실 6.737\n",
            "Every effort moves you,                                                 \n",
            "에포크 6 (Step 000045): 훈련 손실 5.958, 검증 손실 6.751\n",
            "에포크 6 (Step 000050): 훈련 손실 5.939, 검증 손실 6.755\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "에포크 7 (Step 000055): 훈련 손실 5.971, 검증 손실 6.781\n",
            "에포크 7 (Step 000060): 훈련 손실 5.901, 검증 손실 6.788\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "에포크 8 (Step 000065): 훈련 손실 5.847, 검증 손실 6.757\n",
            "에포크 8 (Step 000070): 훈련 손실 5.863, 검증 손실 6.728\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "에포크 9 (Step 000075): 훈련 손실 5.802, 검증 손실 6.680\n",
            "에포크 9 (Step 000080): 훈련 손실 5.728, 검증 손실 6.635\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,\n",
            "에포크 10 (Step 000085): 훈련 손실 5.622, 검증 손실 6.583\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,, the,,,,,,,,, the,,,,,,, the,,, the,,,,,,,,\n"
          ]
        }
      ],
      "source": [
        "# 노트:\n",
        "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요.\n",
        "# import time\n",
        "# start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "# 실행 시간을 계산하고 싶다면 다음 주석을 해제하세요.\n",
        "# end_time = time.time()\n",
        "# execution_time_minutes = (end_time - start_time) / 60\n",
        "# print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204",
      "metadata": {
        "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204"
      },
      "source": [
        "- 여러분의 결과와 손실 값이 조금 다를 수 있습니다. 대체적으로 비슷하다면 (훈련 손실은 1이하이고 검증 손실은 7이하이면) 걱정할 필요가 없습니다.\n",
        "- GPU 하드웨어와 CUDA 버전 또는 파이토치의 신버전에서 바뀐 변화 때문에 차이가 발생할 수 있습니다.\n",
        "- CPU에서 이 예제를 실행하더라도 작은 차이를 볼 수 있습니다. 이런 차이를 만드는 원인 중 하나는 파이토치가 컴파일된 운영체제에 따라 `nn.Dropout`의 동작 방식이 다르기 때문입니다. 자세한 내용은 파이토치 [깃허브 이슈](https://github.com/pytorch/pytorch/issues/121595)를 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "0WSRu2i0iHJE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "0WSRu2i0iHJE",
        "outputId": "595db52d-f949-442f-8d96-e941a24fb0e0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVDZJREFUeJzt3XlcFPX/wPHX7ALLjSAioCJ4Ip4oaopn3plllldqmpWVJ1lmZprZT83Ko7I0O7Qs08zja+aF5ZFh3niLVt6KeCD3vfP7Y2BxBQ0U2IXez8djHjvzmc/MvvkIvnc+89nPKKqqqgghhBDCKuksHYAQQggh7k4StRBCCGHFJFELIYQQVkwStRBCCGHFJFELIYQQVkwStRBCCGHFJFELIYQQVkwStRBCCGHFJFELIYQQVkwStRBlhKIorFmzxtJhCCGKmCRqIayEoij3XIYMGWLpEIUQFmBj6QCEEJorV66Y1pcvX87kyZOJiooylTk4OFgiLCGEhckVtRBWwtvb27S4ubmhKIpZ2dKlS6levTp2dnbUrl2bJUuW3PN8U6dOpWLFikRGRgIQERFBmzZtcHBwoEqVKowePZqkpCRTfX9/f6ZPn87QoUNxcXHBz8+PhQsXmvanp6czcuRIfHx8sLe3x9/fnxkzZtz1/bdt20azZs1wcnKiXLlyhIaGcu7cOdP+n3/+mSZNmmBvb0+1atV45513yMzMNO2Pi4tj2LBheHl54erqysMPP8yhQ4dM+6dMmUKjRo1YsmQJ/v7+uLm50a9fPxISEgrc5kKUBpKohSgFVq9ezZgxY3j11Vc5evQoL774Is8++yxbt27NU1dVVcaMGcNXX33Fzp07adSoEUeOHKFLly706tWLw4cPs3z5cnbu3MnIkSPNjp01axYhISEcPHiQ4cOH8/LLL3Py5EkAPv74Y9auXcuPP/5IVFQU3333Hf7+/vnGm5mZSc+ePWnbti2HDx9m165dDBs2DEVRANi0aRMDBw5k9OjRHD9+nM8//5zFixczbdo008/QvXt3oqOjWb9+Pfv376dx48Z06NCBmzdvmt7n77//Zs2aNaxbt45169axfft23nvvvaJociGshyqEsDqLFi1S3dzcTNstW7ZUX3jhBbM6vXv3Vh955BHTNqCuWLFCHThwoBoYGKheuHDBtG/QoEHqsGHDzI7//fffVZ1Op6akpKiqqqpVq1ZVBw4caNpvNBpVLy8vdf78+aqqquqoUaPUhx9+WDUajf8a/40bN1RA3bZtW777W7durU6fPt2sbMmSJaqPj4+qqqr666+/qq6urmpqaqpZnerVq6uff/65qqqq+vbbb6uOjo5qfHy8af+4cePU5s2b/2t8QpQmco9aiFLgxIkTDBs2zKwsNDSUjz76yKzslVdewWAw8Oeff+Lp6Wkq379/P3/99Rfff/+9qUxVVYxGI2fOnKFOnToANGjQwLQ/p+s9JiYGgCFDhtCpUydq165N165defTRR+ncuXO+8Xp4eDBkyBC6dOlCp06d6NixI3369MHHx8cUz969e01X0ABZWVmkpqaSnJzM/v37SUxMpHz58mbnTUlJ4e+//zZt+/v74+LiYtr28fExxStEWSGJWohSIqfbOIeqqnnKOnXqxA8//MCmTZsYMGCAqdxoNPLiiy8yevToPOf18/Mzrdva2uZ5T6PRCEDjxo05c+YMGzZsYMuWLfTp04eOHTvy008/5RvvokWLGD16NBs3bmT58uW89dZbhIeH89BDD2E0GnnnnXfo1atXnuPs7e0xGo34+Piwbdu2PPvLlStXoHiFKCskUQtRCtSpU4edO3fyzDPPmMoiIiJMV8I5HnvsMXr06MHTTz+NXq+nX79+gJZkjx07Ro0aNR4oDldXV/r27Uvfvn156qmn6Nq1Kzdv3sTDwyPf+sHBwQQHBzNhwgRatGjB0qVLeeihh2jcuDFRUVF3jadx48ZER0djY2Nz1/vgQvxXSKIWohQYN24cffr0MQ2o+vnnn1m1ahVbtmzJU/eJJ55gyZIlDBo0CBsbG5566inGjx/PQw89xIgRI3jhhRdwcnLixIkThIeH88knnxQohjlz5uDj40OjRo3Q6XSsWLECb29vsyvcHGfOnGHhwoU89thj+Pr6EhUVxalTp0wfNCZPnsyjjz5KlSpV6N27NzqdjsOHD3PkyBH+7//+j44dO9KiRQt69uzJzJkzqV27NpcvX2b9+vX07NmTkJCQB2pPIUoTSdRClAI9e/bko48+4oMPPmD06NEEBASwaNEi2rVrl2/9p556CqPRyKBBg9DpdPTq1Yvt27czceJEWrdujaqqVK9enb59+xY4BmdnZ2bOnMnp06fR6/U0bdqU9evXo9Pl/fKIo6MjJ0+e5JtvvuHGjRv4+PgwcuRIXnzxRQC6dOnCunXrmDp1Ku+//z62trYEBgby/PPPA1oX9vr165k4cSJDhw7l2rVreHt706ZNGypWrFj4BhSiFFNUVVUtHYQQQggh8iffoxZCCCGsmCRqIYQQwopJohZCCCGsmCRqIYQQwopJohZCCCGsmCRqIYQQwopJor6Lzz77jICAAOzt7WnSpAm///67pUOyuB07dtCjRw98fX1RFIU1a9aY7VdVlSlTpuDr64uDgwPt2rXj2LFjZnXS0tIYNWoUnp6eODk58dhjj3Hx4kWzOrGxsQwaNAg3Nzfc3NwYNGgQt27dMqtz/vx5evTogZOTE56enowePZr09PTi+LFLzIwZM2jatCkuLi54eXnRs2dPs+dRg7Txg5o/fz4NGjTA1dUVV1dXWrRowYYNG0z7pX2L1owZM1AUhbCwMFOZtPF9sNjjQKzYsmXLVFtbW/WLL75Qjx8/ro4ZM0Z1cnJSz507Z+nQLGr9+vXqxIkT1ZUrV6qAunr1arP97733nuri4qKuXLlSPXLkiNq3b1/Vx8fH7OlGL730klqpUiU1PDxcPXDggNq+fXu1YcOGamZmpqlO165d1Xr16qkRERFqRESEWq9ePfXRRx817c/MzFTr1auntm/fXj1w4IAaHh6u+vr6qiNHjiz2NihOXbp0URctWqQePXpUjYyMVLt37676+fmpiYmJpjrSxg9m7dq16i+//KJGRUWpUVFR6ptvvqna2tqqR48eVVVV2rco7dmzR/X391cbNGigjhkzxlQubVx4kqjz0axZM/Wll14yKwsMDFTfeOMNC0Vkfe5M1EajUfX29lbfe+89U1lqaqrq5uamLliwQFVVVb1165Zqa2urLlu2zFTn0qVLqk6nUzdu3KiqqqoeP35cBdQ///zTVGfXrl0qoJ48eVJVVe0Dg06nUy9dumSq88MPP6gGg0GNi4srlp/XEmJiYlRA3b59u6qq0sbFxd3dXf3yyy+lfYtQQkKCWrNmTTU8PFxt27atKVFLG98f6fq+Q3p6Ovv378/z+L7OnTsTERFhoais35kzZ4iOjjZrN4PBQNu2bU3ttn//fjIyMszq+Pr6Uq9ePVOdXbt24ebmRvPmzU11HnroIdzc3Mzq1KtXD19fX1OdLl26kJaWxv79+4v15yxJcXFxAKYHXkgbF62srCyWLVtGUlISLVq0kPYtQiNGjKB79+507NjRrFza+P7IXN93uH79OllZWXnmE65YsSLR0dEWisr65bRNfu127tw5Ux07Ozvc3d3z1Mk5Pjo6Gi8vrzzn9/LyMqtz5/u4u7tjZ2dXZv6NVFVl7NixtGrVinr16gHSxkXlyJEjtGjRgtTUVJydnVm9ejVBQUGm/+ClfR/MsmXLOHDgAHv37s2zT36H748k6rsoyLN/RV7302531smv/v3UKc1GjhzJ4cOH2blzZ5590sYPpnbt2kRGRnLr1i1WrlzJ4MGD2b59u2m/tO/9u3DhAmPGjGHz5s3Y29vftZ60ceFI1/cdPD090ev1eT5xxcTEyFN77sHb2xvgnu3m7e1Neno6sbGx96xz9erVPOe/du2aWZ073yc2NpaMjIwy8W80atQo1q5dy9atW6lcubKpXNq4aNjZ2VGjRg1CQkKYMWMGDRs25KOPPpL2LQL79+8nJiaGJk2aYGNjg42NDdu3b+fjjz/GxsbG9LNJGxeOJOo72NnZ0aRJE8LDw83Kw8PDadmypYWisn4BAQF4e3ubtVt6ejrbt283tVuTJk2wtbU1q3PlyhWOHj1qqtOiRQvi4uLYs2ePqc7u3buJi4szq3P06FGuXLliqrN582YMBgNNmjQp1p+zOKmqysiRI1m1ahW//fYbAQEBZvuljYuHqqqkpaVJ+xaBDh06cOTIESIjI01LSEgIAwYMIDIykmrVqkkb34+SHbtWOuR8Peurr75Sjx8/roaFhalOTk7q2bNnLR2aRSUkJKgHDx5UDx48qALq7Nmz1YMHD5q+tvbee++pbm5u6qpVq9QjR46o/fv3z/drF5UrV1a3bNmiHjhwQH344Yfz/dpFgwYN1F27dqm7du1S69evn+/XLjp06KAeOHBA3bJli1q5cuVS+bWL27388suqm5ubum3bNvXKlSumJTk52VRH2vjBTJgwQd2xY4d65swZ9fDhw+qbb76p6nQ6dfPmzaqqSvsWh9tHfauqtPH9kER9F59++qlatWpV1c7OTm3cuLHpKzL/ZVu3blWBPMvgwYNVVdW+evH222+r3t7eqsFgUNu0aaMeOXLE7BwpKSnqyJEjVQ8PD9XBwUF99NFH1fPnz5vVuXHjhjpgwADVxcVFdXFxUQcMGKDGxsaa1Tl37pzavXt31cHBQfXw8FBHjhyppqamFuePX+zya1tAXbRokamOtPGDGTp0qOnvukKFCmqHDh1MSVpVpX2Lw52JWtq48BRVVVXLXMsLIYQQ4t/IPWohhBDCikmiFkIIIayYJGohhBDCikmiFkIIIayYJGohhBDCikmiFkIIIayYJOp7SEtLY8qUKaSlpVk6lDJJ2rd4SfsWP2nj4iXtq5HvUd9DfHw8bm5uxMXF4erqaulwyhxp3+Il7Vv8pI2Ll7SvRq6ohRBCCCsmiVoIIYSwYmX+edSZmZkcPHiQihUrotMV7nNJQkICAJcuXSI+Pr44wvtPk/YtXtK+xU/auHiV5fY1Go1cvXqV4OBgbGzunYrL/D3qvXv30qxZM0uHIYQQQuSxZ88emjZtes86Zf6KOucB4Xv27MHHx8fC0QghhBDaM7abNWtmylH3UuYTdU53t4+PD5UrV7ZwNEIIIUSugtySlcFkQgghhBWzaKLesWMHPXr0wNfXF0VRWLNmjdn+VatW0aVLFzw9PVEUhcjISIvEKYQQQliKRRN1UlISDRs2ZN68eXfdHxoaynvvvVfCkQkhhBDWwaL3qLt160a3bt3uun/QoEEAnD17toQiEkL812VlZZGRkWHpMEQpZ2tri16vL5JzlbnBZGlpaWbzwuZ8D6+o3EhMo7yzoUjPKYSwPFVViY6O5tatW5YORZQR5cqVw9vbG0VRHug8ZS5Rz5gxg3feeafIz5uakcXEVZE4HVvK6Cfa4Rnco8jfQwhhOTlJ2svLC0dHxwf+z1X8d6mqSnJyMjExMQAP/NXgMpeoJ0yYwNixY03bly5dIigo6IHPa7DRUf/SjwzRfcnN9eugXkewdXjg8wohLC8rK8uUpMuXL2/pcEQZ4OCg5YeYmBi8vLweqBu8zH09y2Aw4OrqalpcXFyK5LyKotC45xiuqB54ZERzffOHRXJeIYTl5dyTdnR0tHAkoizJ+X160DEPZS5RF6cG1XxZ7z0cAJd9n8Ct8xaOSAhRlKS7WxSlovp9smiiTkxMJDIy0vT96DNnzhAZGcn581oCvHnzJpGRkRw/fhyAqKgoIiMjiY6OtlTItHvyJXYbAzGoadxcM95icQghhPhvsGii3rdvH8HBwQQHBwMwduxYgoODmTx5MgBr164lODiY7t27A9CvXz+Cg4NZsGCBxWKu7uXCn7XHk6UqeJxdj/rPNovFIoQQxaFdu3aEhYUVuP7Zs2dLZFKqbdu2oSjKf25kvkUHk7Vr1457PbxryJAhDBkypOQCKqB+PR5h2YedGKBsJmnNaziP+RP0ZW5cnhDCyv1b1+rgwYNZvHhxoc+7atUqbG1tC1y/SpUqXLlyBU9Pz0K/l/h3kl3uQ0VXe240e42beyPwiD+Ncc8X6Fq8bOmwhBD/MVeuXDGtL1++nMmTJxMVFWUqyxl5nCMjI6NACdjDw6NQcej1ery9vQt1jCg4GUx2nwZ3aMynytMAZP46DZKuWzgiIcR/jbe3t2lxc3NDURTTdmpqKuXKlePHH3+kXbt22Nvb891333Hjxg369+9P5cqVcXR0pH79+vzwww9m572z69vf35/p06czdOhQXFxc8PPzY+HChab9d3Z953RR//rrr4SEhODo6EjLli3NPkQA/N///R9eXl64uLjw/PPP88Ybb9CoUaNCtcHKlSupW7cuBoMBf39/Zs2aZbb/s88+o2bNmtjb21OxYkWeeuop076ffvqJ+vXr4+DgQPny5enYsSNJSUmFev+SIIn6Prk52OLTfhhHjf7YZSaQGT7F0iEJIYqQqqokp2daZLnXLcHCGj9+PKNHj+bEiRN06dKF1NRUmjRpwrp16zh69CjDhg1j0KBB7N69+57nmTVrFiEhIRw8eJDhw4fz8ssvc/LkyXseM3HiRGbNmsW+ffuwsbFh6NChpn3ff/8906ZNY+bMmezfvx8/Pz/mz59fqJ9t//799OnTh379+nHkyBGmTJnCpEmTTN39+/btY/To0UydOpWoqCg2btxImzZtAK03on///gwdOpQTJ06wbds2evXqVaRtX1Sk6/sBDGxZjTE7X+DzjInoI7+DpkOhUmNLhyWEKAIpGVkETd5kkfc+PrULjnZF899zWFgYvXr1Mit77bXXTOujRo1i48aNrFixgubNm9/1PI888gjDh2tfTx0/fjxz5sxh27ZtBAYG3vWYadOm0bZtWwDeeOMNunfvTmpqKvb29nzyySc899xzPPvsswBMnjyZzZs3k5iYWOCfbfbs2XTo0IFJkyYBUKtWLY4fP84HH3zAkCFDOH/+PE5OTjz66KO4uLhQtWpV0+DlK1eukJmZSa9evahatSoA9evXL/B7lyS5on4A9rZ6OnZ5nFVZrVBQydg609IhCSGEmZCQELPtrKwspk2bRoMGDShfvjzOzs5s3rzZ9LXYu2nQoIFpPaeLPWeKzIIckzONZs4xUVFRNGvWzKz+ndv/5sSJE4SGhpqVhYaGcvr0abKysujUqRNVq1alWrVqDBo0iO+//57k5GQAGjZsSIcOHahfvz69e/fmiy++IDY2tlDvX1LkivoB9WpcmQHbn+NqrDup5cJ4xdIBCSGKhIOtnuNTu1jsvYuKk5OT2fasWbOYM2cOc+fOpX79+jg5OREWFkZ6evo9z3PnIDRFUTAajQU+JmeE+u3H3DlqvbDdzqqq3vMcLi4uHDhwgG3btrF582YmT57MlClT2Lt3L+XKlSM8PJyIiAg2b97MJ598wsSJE9m9ezcBAQGFiqO4yRX1A9LrFJ7rFsrMzP58vvsa0XGplg5JCFEEFEXB0c7GIktxzpD2+++/8/jjjzNw4EAaNmxItWrVOH36dLG9393Url2bPXv2mJXt27evUOcICgpi586dZmURERHUqlXLNLe2jY0NHTt25P333+fw4cOcPXuW3377DdD+jUNDQ3nnnXc4ePAgdnZ2rF69+gF+quIhV9RFoGMdL0KqurPvXCwfbYliRksFfBr8+4FCCFHCatSowcqVK4mIiMDd3Z3Zs2cTHR1NnTp1SjSOUaNG8cILLxASEkLLli1Zvnw5hw8fplq1agU+x6uvvkrTpk1599136du3L7t27WLevHl89tlnAKxbt45//vmHNm3a4O7uzvr16zEajdSuXZvdu3fz66+/0rlzZ7y8vNi9ezfXrl0r8XYoCLmiLgKKovBGt0AcSaXXoRdQv2gP105ZOiwhhMhj0qRJNG7cmC5dutCuXTu8vb3p2bNniccxYMAAJkyYwGuvvUbjxo05c+YMQ4YMwd7evsDnaNy4MT/++CPLli2jXr16TJ48malTp5omyipXrhyrVq3i4Ycfpk6dOixYsIAffviBunXr4urqyo4dO3jkkUeoVasWb731FrNmzaJbt27F9BPfP0W1xrHoRejixYtUqVKFCxcuULly5WJ9r+e/2Ue/v16jtc0JDE/Oh3q9/v0gIYTFpaamcubMGQICAgqVKETR6tSpE97e3ixZssTSoRSJe/1eFSY3Sdd3EXq9a22Gzn2WrAyFz1zbE2zpgIQQwkolJyezYMECunTpgl6v54cffmDLli2Eh4dbOjSrI13fRahWRRdaNG7EFcrz3oaTVvnFeSGEsAaKorB+/Xpat25NkyZN+Pnnn1m5ciUdO3a0dGhWR66oi9grnWrxv0OX2X3mJpG/ryPY+RY0HmTpsIQQwqo4ODiwZcsWS4dRKsgVdRHzLefA4BZVaaqcJPi3gajrx0HcRUuHJYQQopSSRF0MhrerwUlDXXYbA1EyU2DzW5YOSQghRCkliboYuDvZ8VLbGryT8QxZ6ODYajjzu6XDEkIIUQpJoi4mQ0MDuO5cm6WZD2sFG8ZDVqZlgxJCCFHqSKIuJg52esI61mJWZm9u4Qwxx2Df15YOSwghRCkjiboY9QmpjIenNx9m9NYKtv4fJF23bFBCCCFKFUnUxchGr2Ncl9oszerASbUqpMbBb+9aOiwhhDDTrl07wsLCTNv+/v7MnTv3nscoisKaNWse+L2L6jz3MmXKFBo1alSs71GcLJqod+zYQY8ePfD19c33H0tVVaZMmYKvry8ODg60a9eOY8eOWSbY+9S1njf1q3gwKX2wVrD/G7h80LJBCSHKhB49etx1gpBdu3ahKAoHDhwo9Hn37t3LsGHDHjQ8M3dLlleuXLHK+bWtiUUTdVJSEg0bNmTevHn57n///feZPXs28+bNY+/evXh7e9OpUycSEhJKONL7pygKb3QNZK8ayP+yQgEV1r8OMmuZEOIBPffcc/z222+cO3cuz76vv/6aRo0a0bhx40Kft0KFCjg6OhZFiP/K29sbg8FQIu9VWlk0UXfr1o3/+7//o1evvA+vUFWVuXPnMnHiRHr16kW9evX45ptvSE5OZunSpRaI9v61qF6etrUqMD2jP2mKPVzcA4eXWzosIUQp9+ijj+Ll5cXixYvNypOTk1m+fDnPPfccN27coH///lSuXBlHR0fq16/PDz/8cM/z3tn1ffr0adq0aYO9vT1BQUH5zsc9fvx4atWqhaOjI9WqVWPSpElkZGQAsHjxYt555x0OHTqEoigoimKK+c7e1CNHjvDwww/j4OBA+fLlGTZsGImJiab9Q4YMoWfPnnz44Yf4+PhQvnx5RowYYXqvgjAajUydOpXKlStjMBho1KgRGzduNO1PT09n5MiR+Pj4YG9vj7+/PzNmzDDtnzJlCn5+fhgMBnx9fRk9enSB3/t+WO096jNnzhAdHU3nzp1NZQaDgbZt2xIREWHByO7P611rcxUP5qb31Aq2TpOvawlRGqQnFX65/W87K1Mry0gp2HkLwcbGhmeeeYbFixebPVtgxYoVpKenM2DAAFJTU2nSpAnr1q3j6NGjDBs2jEGDBrF79+4CvYfRaKRXr17o9Xr+/PNPFixYwPjx4/PUc3FxYfHixRw/fpyPPvqIL774gjlz5gDQt29fXn31VerWrcuVK1e4cuUKffv2zXOO5ORkunbtiru7O3v37mXFihVs2bKFkSNHmtXbunUrf//9N1u3buWbb75h8eLFeT6s3MtHH33ErFmz+PDDDzl8+DBdunThscce4/Tp0wB8/PHHrF27lh9//JGoqCi+++47/P39Afjpp5+YM2cOn3/+OadPn2bNmjXUr1+/wO99P6x2ru/o6GgAKlasaFZesWLFfLt5cqSlpZGWlmbatpZu8rq+bvRs5MtXkd0IKZdAh0Hvgt5qm18IkWO6b+GP6b0Y6j6hrZ/8GVYMgaqt4NlfcuvMrQ/JN/IeOyWuUG81dOhQPvjgA7Zt20b79u0Brdu7V69euLu74+7uzmuvvWaqP2rUKDZu3MiKFSto3rz5v55/y5YtnDhxgrNnz5oexzh9+vQ895Xfeit3BkZ/f39effVVli9fzuuvv46DgwPOzs7Y2Njg7e191/f6/vvvSUlJ4dtvv8XJyQmAefPm0aNHD2bOnGnKB+7u7sybNw+9Xk9gYCDdu3fn119/5YUXXihQm3344YeMHz+efv36ATBz5ky2bt3K3Llz+fTTTzl//jw1a9akVatWKIpC1apVTceeP38eb29vOnbsiK2tLX5+fjRr1qxA73u/rPaKOoeiKGbbqqrmKbvdjBkzcHNzMy1BQUHFHWKBvdq5NqrejuduDOCPWDdLhyOEKAMCAwNp2bIlX3+tzdPw999/8/vvvzN06FAAsrKymDZtGg0aNKB8+fI4OzuzefNmzp8/X6DznzhxAj8/P7NnJrdo0SJPvZ9++olWrVrh7e2Ns7MzkyZNKvB73P5eDRs2NCVpgNDQUIxGI1FRUaayunXrotfrTds+Pj7ExMQU6D3i4+O5fPkyoaGhZuWhoaGcOHEC0LrXIyMjqV27NqNHj2bz5s2mer179yYlJYVq1arxwgsvsHr1ajIzi7d31Gov6XI+dUVHR+Pj42Mqj4mJyXOVfbsJEyYwduxY0/alS5esJllX8XBkQPOqLI44y3sbTvK/EaHobpwCz1pwjw8fQggLevNy4Y/R3zY4KrCHdg7ljuuisCMPFtdtnnvuOUaOHMmnn37KokWLqFq1Kh06dABg1qxZzJkzh7lz51K/fn2cnJwICwsjPT29QOfO73G9d14s/fnnn/Tr14933nmHLl264ObmxrJly5g1a1ahfo57XYjdXm5ra5tnn9FoLNR73esisHHjxpw5c4YNGzawZcsW+vTpQ8eOHfnpp5+oUqUKUVFRhIeHs2XLFoYPH84HH3zA9u3b88RVVKz2ijogIABvb2+zQQvp6els376dli1b3vU4g8GAq6uraXFxcSmJcAts5MM1cLLTc+TSLc4veQk+bQZRGywdlhDibuycCr/cfltLb6OV2ToU7Lz3oU+fPuj1epYuXco333zDs88+a0o6v//+O48//jgDBw6kYcOGVKtWzXQvtiCCgoI4f/48ly/nfmDZtWuXWZ0//viDqlWrMnHiREJCQqhZs2aeW5R2dnZkZWX963tFRkaSlJR7r/6PP/5Ap9NRq1atAsd8L66urvj6+rJz506z8oiICOrUqWNWr2/fvnzxxRcsX76clStXcvPmTUB7ROdjjz3Gxx9/zLZt29i1axdHjhTdB687WfSKOjExkb/++su0febMGSIjI/Hw8MDPz4+wsDCmT59OzZo1qVmzJtOnT8fR0ZGnn37aglE/GE9nA8PaVGfOllP8cTEDf4BL+yDwEQtHJoQorZydnenbty9vvvkmcXFxDBkyxLSvRo0arFy5koiICNzd3Zk9ezbR0dFmSeleOnbsSO3atXnmmWeYNWsW8fHxTJw40axOjRo1OH/+PMuWLaNp06b88ssvrF692qyOv7+/6f/4ypUr4+LikudrWQMGDODtt99m8ODBTJkyhWvXrjFq1CgGDRp0z57Uwho3bhxvv/021atXp1GjRixatIjIyEi+//57AObMmYOPjw+NGjVCp9OxYsUKvL29KVeuHIsXLyYrK4vmzZvj6OjIkiVLcHBwMLuPXdQsekW9b98+goODCQ4OBmDs2LEEBwczefJkAF5//XXCwsIYPnw4ISEhXLp0ic2bN1vdVXJhPd86AE9nO6YldGfDQ0ugw2RLhySEKOWee+45YmNj6dixI35+fqbySZMm0bhxY7p06UK7du3w9vamZ8+eBT6vTqdj9erVpKWl0axZM55//nmmTZtmVufxxx/nlVdeYeTIkTRq1IiIiAgmTZpkVufJJ5+ka9eutG/fngoVKuT7FTFHR0c2bdrEzZs3adq0KU899RQdOnS461wb92v06NG8+uqrvPrqq9SvX5+NGzeydu1aatasCWgffGbOnElISAhNmzbl7NmzrF+/Hp1OR7ly5fjiiy8IDQ2lQYMG/Prrr/z888+UL1++SGO8naLmdwOiDLl48SJVqlThwoULZoMhLO2biLO8vfYYns4Gto9rh5PBaocLCFHmpaamcubMGQICArC3t7d0OKKMuNfvVWFyk9Xeoy7r+jfzw8/DkeuJaXy98wzEnoVdn1o6LCGEEFZGErWF2NnoeLWzNjhi+Y5I1M9awKY34dQmC0cmhBDCmkiitqAeDXyp6+vKxTRH/vR4XCtc9wqkxls2MCGEEFZDErUF6XQK47sGAvDixa5kulWF+EuwZYplAxNCCGE1JFFbWOuanrSsXp74LFsWuoVphfu+grN/WDQuIYQQ1kEStYUpisIb3bSr6vdPVeRGLW3uWdaOyjuJvxCiWBV2dish7qWofp/kO0FWoEHlcvQKrsSqg5cYfbMX3zlvQ7n5N2yfCR2nWDo8Ico8Ozs7dDodly9fpkKFCtjZ2d3zmQJC3IuqqqSnp3Pt2jV0Oh12dnYPdD5J1FZifLdANh2L5o+LmexqPZGWe0fBHx9DUE/wbWTp8IQo03Q6HQEBAVy5csVsqkwhHoSjoyN+fn7odA/WeS2J2kpUdLVn5MM1mbnxJGMifYmo0xPbE2tg7Uh4YSvoi2eydyGExs7ODj8/PzIzM/91Tmoh/o1er8fGxqZIemYkUVuRoa38Wb73PGdvJDPfYRij7bdB9BGI+Bhav2rp8IQo8xRFwdbWttiegiTE/ZDBZFbEYKNn0qPaIznn7Y7nWqt3tB3bZsL1gj/tRgghRNkhidrKPBzoRdtaFUjPMvLG6SCo3gGy0uRRmEII8R8lidrKKIrCpEeDsNEp/Bp1jV11J8GgNRA62tKhCSGEsABJ1FaohpczQ1r6AzBxaxzpVdtaNiAhhBAWI4naSo3uWBNPZzv+uZbEt7vOaoVxF2H7+1C2n0wqhBDiNpKorZSrvS2vd9FmLPtoy2mu3bwJn7eBrdPgyAoLRyeEEKKkSKK2Yk81qUyDym4kpGXywW8X4KGXoUpz8Glo6dCEEEKUEEnUVkynU3i7R10AVuy/yGH/Z+HZjVChtoUjE0IIUVIkUVu5JlXd6RVcCVWFKeuiMHLbLDfpSZYLTAghRImQRF0KjO8WiKOdngPnb7Em8pL2VK1NE+HT5pAaZ+nwhBBCFCNJ1KWANg94DQDe23CSxLQMiFoPcRcg/G0LRyeEEKI4WX2iTkhIICwsjKpVq+Lg4EDLli3Zu3evpcMqcc+1CqBqeUdiEtL4dOdl6PGxtmP/Iji707LBCSGEKDZWn6iff/55wsPDWbJkCUeOHKFz58507NiRS5cuWTq0EmWw0TOpuzYP+Fe/n+GsS2NoMkTbuXaU1h0uhBCizLHqRJ2SksLKlSt5//33adOmDTVq1GDKlCkEBAQwf/58S4dX4jrU8aJN9jzg//fLceg0FVx84OY/sG2GpcMTQghRDKw6Uec8F9be3t6s3MHBgZ078+/uTUtLIz4+3rQkJCSURKglQlEUJmfPA77lRAzbz6fDo3O0nRGfwKUDlg1QCCFEkbPqRO3i4kKLFi149913uXz5MllZWXz33Xfs3r2bK1eu5HvMjBkzcHNzMy1BQUElHHXxquHlzODsecCn/nyMjBpdoN6ToBq1LvCsDMsGKIQQokhZdaIGWLJkCaqqUqlSJQwGAx9//DFPP/00er0+3/oTJkwgLi7OtBw/fryEIy5+Y7LnAf/7WhLfRJyFrjPBwR2uHoU/PrJ0eEIIIYqQ1Sfq6tWrs337dhITE7lw4QJ79uwhIyODgICAfOsbDAZcXV1Ni4uLSwlHXPxc7W0Z10WbneyjLae5prpqyRpg+0y4dsqC0QkhhChKVp+oczg5OeHj40NsbCybNm3i8ccft3RIFtW7SRXqV9LmAf9wUxQ06AM1OkFWOqwdCUajpUMUQghRBKw+UW/atImNGzdy5swZwsPDad++PbVr1+bZZ5+1dGgWpdMpTHlMu//+4/4LHLkUrw0ss3OGC7th75cWjlAIIURRsPpEHRcXx4gRIwgMDOSZZ56hVatWbN68GVtbW0uHZnFNqnrwRPY84G+vPYrqVhk6TgHfYKja0tLhCSGEKAKKqqqqpYMoThcvXqRKlSpcuHCBypUrWzqcInc1PpX2H24jOT2LOX0b8kRDX20EuN7G0qEJIYS4i8LkJqu/ohb3VtHVnhHtc+cBT8q4I0mnJVooMiGEEEVBEnUZ8FyrAPw8HLkan8anW//SCjPTYMs78HEwJF6zbIBCCCHumyTqMsDeVs+kR7WBZV/+foZzN5JA0cFf4ZAUA0d/snCEQggh7pck6jKiYx0vWtf0JD3LyLvrToDeFh7/FPosgYdetnR4Qggh7tN9JeoLFy5w8eJF0/aePXsICwtj4cKFRRaYKBxFUXi7R8484FfZceoa+DSEoMcsHZoQQogHcF+J+umnn2br1q0AREdH06lTJ/bs2cObb77J1KlTizRAUXA1vFx4poU/AFPXHScj67ZJTxJjYNt7MhGKEEKUMveVqI8ePUqzZs0A+PHHH6lXrx4REREsXbqUxYsXF2V8opDGdKxJeSc7/opJ5Ntd57TCzDT4ooP2KMw9n1s2QCGEEIVyX4k6IyMDg8EAwJYtW3jsMa17NTAw8K5PtRIlw80hdx7wueGnuJ6YBjYGCB2tVQifDNFHLRihEEKIwrivRF23bl0WLFjA77//Tnh4OF27dgXg8uXLlC9fvkgDFIXXO6QK9Sq55s4DDtD0eajZRZsLfNULkJFi2SCFEEIUyH0l6pkzZ/L555/Trl07+vfvT8OGDQFYu3atqUtcWI5epzClR10Alu+7wJGLcaAo2ihwpwoQcxy2TLFskEIIIQrkvhJ1u3btuH79OtevX+frr782lQ8bNowFCxYUWXDi/oX4e9CzkS+qClN+PoaqquBcAXrO1yrsXgCnwy0bpBBCiH91X4k6JSWFtLQ03N3dATh37hxz584lKioKLy+vIg1Q3L83utXB0U7P/nOxrDpwSSus2Qmavaitrxkus5YJIYSVu69E/fjjj/Ptt98CcOvWLZo3b86sWbPo2bMn8+fPL9IAxf3zdrNn5MPaPOBT1x0nJj5V29HpHahQR5u1bO1IKNvPZRFCiFLtvhL1gQMHaN26NQA//fQTFStW5Ny5c3z77bd8/PHHRRqgeDAvtK5G/UpuxKVk8ObqI1oXuK0DPPkl6A1waiPs+8rSYQohhLiL+0rUycnJuLi4ALB582Z69eqFTqfjoYce4ty5c0UaoHgwtnodH/ZuiJ1ex5YTMbld4N71tCtrgE0T4VqU5YIUQghxV/eVqGvUqMGaNWu4cOECmzZtonPnzgDExMTg6upapAGKB1fb24WwTjUBbWBZdFx2F3izF6F6B8hMhZXPaROjCCGEsCr3lagnT57Ma6+9hr+/P82aNaNFixaAdnUdHBxcpAGKojGsdTUaVilHQmomb6w6rHWB63TQ8zNwLA/uAVrCFkIIYVUUVb2/kUTR0dFcuXKFhg0botNp+X7Pnj24uroSGBhYpEE+iIsXL1KlShUuXLhA5cqVLR2ORf0Vk8AjH+8kPdPIzCfr07epn7bj1gVwq6x911oIIUSxK0xuuu/HXHp7exMcHMzly5e5dEm779msWTOrStLCXA0vF17rXAuAd9ed4NKt7NnJylXJTdKqKl3gQghhRe4rURuNRqZOnYqbmxtVq1bFz8+PcuXK8e6772KUpzNZtedaVaNJVXcS0zIZ/1N2F3iOlFj46Vn4aah8ZUsIIazEfSXqiRMnMm/ePN577z0OHjzIgQMHmD59Op988gmTJk0q6hhFEdLrFD54qgH2tjp2/nWdpXvO5+68dR5OrNO+snVVHtwhhBDW4L4S9TfffMOXX37Jyy+/TIMGDWjYsCHDhw/niy++KNLHXGZmZvLWW28REBCAg4MD1apVY+rUqXLV/oCqVXDm9S7aLYppv5zgws1kbYdPQ+gxF57bDN71LRegEEIIk/tK1Ddv3sz3XnRgYCA3b9584KByzJw5kwULFjBv3jxOnDjB+++/zwcffMAnn3xSZO/xXzWkpT/N/D1ITs9i3E+HMBqzu7qDB0KlJpYNTgghhMl9JeqGDRsyb968POXz5s2jQYMGDxxUjl27dvH444/TvXt3/P39eeqpp+jcuTP79u0rsvf4r9LpFD7o3QAHWz1//nOTJX/mM1HN1WOw54uSD04IIYSJzf0c9P7779O9e3e2bNlCixYtUBSFiIgILly4wPr164ssuFatWrFgwQJOnTpFrVq1OHToEDt37mTu3Ll3PSYtLY20tNxRywkJCUUWT1lTtbwTEx4JZPL/jvHehpO0rVUBf08nbefNM7Cwvfb8aq8g8A+1bLBCCPEfdV9X1G3btuXUqVM88cQT3Lp1i5s3b9KrVy+OHTvGokWLiiy48ePH079/fwIDA7G1tSU4OJiwsDD69+9/12NmzJiBm5ubaQkKCiqyeMqigc2r0rJ6eVIy7ugC9wiABr0BFVYN00aECyGEKHH3PeFJfg4dOkTjxo3JysoqkvMtW7aMcePG8cEHH1C3bl0iIyMJCwtj9uzZDB48ON9j7ryivnTpEkFBQTLhyT1cuJlM17k7SErPYtKjQTzXKkDbkZYIn7eGm/9A3SfgqUUyKYoQQhSBEpnwpCSMGzeON954g379+lG/fn0GDRrEK6+8wowZM+56jMFgwNXV1bTkPDxE3F0VD0cmdtd6Ht7feJK/ryVqOwzO0OtLUPRwbDUcWmbBKIUQ4r/JqhN1cnKyaXrSHHq9Xr6eVQz6N6tC65qepGUaeW3FIbJyusArN4H2E7T19a9pV9dCCCFKjFUn6h49ejBt2jR++eUXzp49y+rVq5k9ezZPPPGEpUMrcxRFYeaTDXAx2HDw/C2+/P22hNxqLPi1gPRE7X51VqblAhVCiP+YQo367tWr1z3337p160FiySNnprPhw4cTExODr68vL774IpMnTy7S9xEa33IOTHo0iNdXHmZW+CkeDvSiZkUX0Omh10KYHwoX98KOD3KvsoUQQhSrQg0me/bZZwtUryhHfj8oeXpW4aiqytDFe9kadY2Gld1Y+XJLbPTZHS9HftKeW63o4NmN4NfcssEKIUQpVZjcVKSjvq2RJOrCi45LpfOc7cSnZjKuS21GtK+Ru3PVMDi8HMr5wUt/gL2r5QIVQohSqsyM+haW4e1mz5TH6gIwd8spTkbH5+585EMoV1V7gMf6cRaKUAgh/jskUYt8PRFciY51KpKRpfLqj4fIyMoeaW/vCr2+AJ0tuPqAjMAXQohiJYla5EtRFKb3qkc5R1uOXY7ns61/5+70aw6jD0LHKaCTXyEhhChO8r+suCsvF3umPl4PgE9+O82xy3G5O8tVyV1PjdPmBhdCCFHkJFGLe+rRwIdu9bzJNGpd4OmZd3R1J12HxY/CNz0g7qJlghRCiDJMErW4J0VReLdnPTyc7DgZncAnv502r6AaISMZMlMh5ZZFYhRCiLJMErX4V57OBt7N7gL/bNvfHL54K3ensxc88z94dgN417NMgEIIUYZJohYF0r2BD4828CEruws8LfO2J6S5VQbPmrnblw5oT94SQgjxwCRRiwKb+ng9PJ3tOB2TyNwtp/Ov9PdvsOgRWNYfMlJLNkAhhCiDJFGLAvNwsmP6E/UB+Hz73xw8H5u3kr2bNjf4mR2wYghkZZRskEIIUcZIohaF0rmuN08EV8KowqsrDpGakWVeoVIT6L8MbOzh1AZY/RIYs/I/mRBCiH8liVoU2ts9gvByMfDPtSRmbY7KWyGgNfRZAjobOPoT/DIWyvaU8kIIUWwkUYtCK+dox4xeWhf4lzvPEH78at5KtTprU40qOti/GDa/JclaCCHugyRqcV861KnIwIf8UFUYs+wgxy/H561Urxf0+Fhb3zVPe461EEKIQpFELe7b2z3qElqjPMnpWTz/zV5i4vMZ5d14EHSZoa1vnQZ/zi/ZIIUQopSTRC3um61ex2dPN6FaBScux6Xywrf7SEnPZ+BYi+HQ7k1tfeMbcGBJyQYqhBClmCRq8UDcHG35enBTyjnacuhiHK+uiMRozOdedNvXocVIbf3n0XBsdckGKoQQpZQkavHA/D2d+HxgE2z1CuuPRDNny6m8lRQFOv8fNB6szQ9+OrzkAxVCiFJIErUoEs2rlTdNhvLJb3+x+mA+T9JSFHh0Djz+KTw2r4QjFEKI0snqE7W/vz+KouRZRowYYenQxB16h1Th5XbVARj/0xH2nb2Zt5JOD8EDQZf9q2fMkmdZCyHEPVh9ot67dy9XrlwxLeHhWpdp7969LRyZyM+4zrXpUrci6VlGhi3Zz/kbyXevnJUBq4bBF+3h6vGSC1IIIUoRq0/UFSpUwNvb27SsW7eO6tWr07ZtW0uHJvKh0ynM6duIepVcuZmUznPf7CU+9S7zfWemQexZSEuAG3+VaJxCCFFaWH2ivl16ejrfffcdQ4cORVEUS4cj7sLRzoYvn2lKRVcDp2MSGfH9ATKzjHkrGpxhwAoYuBKCHiv5QIUQohQoVYl6zZo13Lp1iyFDhty1TlpaGvHx8aYlISGh5AIUJt5u9nw1uCkOtnp+P32dqevu0rXt6AHV2uVux12CxGslEqMQQpQGpSpRf/XVV3Tr1g1fX9+71pkxYwZubm6mJSgoqAQjFLerV8mNuf0aoSjw7a5zfBNx9t4H3Pgbvu4K3z0BKbdKIkQhhLB6pSZRnzt3ji1btvD888/fs96ECROIi4szLcePyyAlS+pS15vxXQMBeOfnY2yLirl7ZVWFzBSIPgJL+0B6UglFKYQQ1qvUJOpFixbh5eVF9+7d71nPYDDg6upqWlxcXEooQnE3L7apRu8mlTGqMHLpQaKi73I7wrMGDFoD9m5wYTd80gQ2T4LooyUarxBCWJNSkaiNRiOLFi1i8ODB2NjYWDocUUiKojDtifo0C/AgMS2T577Zy/XEtPwre9eDgavAqQIkXIGIj2FBKMwPhT8+gvjLJRu8EEJYWKlI1Fu2bOH8+fMMHTrU0qGI+2Rno+PzgU3wL+/IxdgUhn27j9SMfB7gAVA5BF45Bn2/gzo9QG8HV49C+GSYHQTfPAaRS7WvdQkhRBmnqKqazxMUyo6LFy9SpUoVLly4QOXKlS0dzn/e39cSeeLTP4hPzeTxRr7M7dvo379qlxILx9bA4R/hfERuua0TjD0ODuWKM2RRlsRfhowUyEiGjFRtTITpNXvJygA1S5s1TzVC9fbgrU2Py81/IPIHcPaCZi/knnfHB5AYo9U3ZmnHq0YwGs3PZWMPdk5g5wjVH879xkNaAvyzHexdIaBN7nlTboHOBmwdc2fzE2VCYXKT9COLElW9gjPzBzZh8Nd7+F/kZapXcGZ0h5r3PsjBHUKe1ZbYs3BkBRxaDq4+5kl675fgGwy+jbV5xcW/U1XITNWSkzEz+zVDe3WtBDZ2Wr24SxB3QbslUV6bJpaMVDi9KZ9jM7VXY6aWoFC1JKWq2tKwH7hX1c5xYS9ErQevIGjQOzemTRPvOM54x3aWeaLNSIH2b4J/qHaO4/+DtaPB7yF4ennuz/tpc0iLL1wb2c3OTdSx52DH++BV1zxRH1pW+El77FxyE3XsOVg+AJy8YNzp3Do/9IPzu7R1W0ctyee8mtadtcRv66B9eA1oA4GPaMdkpGhtYeek9U7liL+s/fvYOmUf5yB/M1ZMErUocaE1PHm3Zz0mrDrC7PBTBHg60aPh3b9yZ8bdH9qMg9avQWpcbnlCNKwfp/1HPjoSPAKKI/TSISNFS5AGZ2078RocWgpJ1yDpevbrbetZ6fmfZ/hu8NJG7HPgG9g+E5o+D91naWVpCfDjM4WPr2rL3ER9JRJ2zoagx3MTNcCfnxb+vAlXzLdTb5n/jgAYXLVXG3uwtdcSnY29lqhssrf1ttqc9Ipee835YALgVgWavqB9SLxdyFCt50fRg6LTrn5N6/rc9cxU7dsMGcnaLZ4cOhuo3Cxv71BGsvl6xj2m5M2ht8lN1EnXYfWL2s/21tXcOutegVMbzY+zzUn2jubrBhftw3JAa22eftA+LJ3apMVbKUR7T1FspHWFRfRv5sffMYl8ufMMr604RGV3B4L93At+AkUx/08tIwXqPqElntuT9Nbp4OIDdXtq/9mURpnpWhJIvp5/su38rjZSHmDjBPjzM2jzOjw8UStLi9fu7xeIkp2obLWr1hyOnuBRDRzL55bZGMCvhZZkco7JSXI564pe+7dSFC1RoYCLd+45KtaD5i9rgwhNISgQGqbVv/2427cVBWwctGSb81q5We45qrWHEXtyE3OOsccK2A534VkDun+Yt7zFAz4kyCsQns/n0a8vbNN6DdKTIT1RS9TpSbnJPmc9PSm3S79qy9zjFZ3WFjq9+XkVPegNkHXboE7TB4Eb+cdoY5ebqNMS4Ie+2vrE6NxE/XOY9gHAvpz295nz6uCetyzn1dETnG77vRJ5yD1qYTFZRpVh3+7j15MxeDob+N/IUCqVc3iwk6pqbhde8k2YVVu7YtTbQa0u0KAv1OysJRlLun5a6yp19wevOlrZrfNaQk2J1WJPuQUpN7X/oO9lxB6oUFtb3zoDtr+nXeE9OkcrS0uAX14DJ0+t69q0ZG/bu2ntk5NkxX+HMeu2e/bJ2np6cu52epL2+5N6S7s9UbOTdlziNVjaW6s7ck/u+Zb2g1MbChdD0OPQ59vseIzw2UPaVfzAn3I/XEdthGsntN9V01LOfNvSf9OFVJjcJIlaWFRiWiZPzY/gZHQCgd4u/PRyS5wNRdTRkxoH+xdr97NjbruSMnVxZicn09WgnXZlMGhN7tX6ni/g79+gfm+o10sri7+iDR4yOzZ7yUy7LdHGaok2JVZLuqP2a4OQANa/Dns+h9avQofsq92b/8DHwXf5YRTtataUYG9Luo2fyb1KTY0HVO1KUu45ipIWfwUSr2qJPeVW9mvsbeu3vabEar09QT2hx1zt+NR4eK+Ktj7xqtZTArD6JTj0w73f28bBPHEHtM792wI48K32d1+ra+5toawMrUfIAn8rMphMlBrOBhu+HtKUxz/9g5PRCYz+4SBfPBOCXlcEfzj2bhA6Rluij8LhZXDkJ+1eZmZqwc4RfVgb7FSpcW5Z0jXY91Xh40mJzU3U5atrg96cvHL3O1eErjO1qwhHD+01Z7F3K9jVrr3rv9cRori4+uS9f18Ytg4wZL32ITsnSYPWna/otPLUuNzxB6lxuR9OM1MgMQUSo3NjyWE0ws9jtDEsr0blJurNk2DPwvz/5hxytsvl7nf2hoolPy21XFELqxB54RZ9P99FWqaR51oFMOnRYvpjMGZpI8ez0rVP07ePcs5K10bCVu+Qe8/tXARci8oeTd5IK0uIhn2Lbjsu5xzZXewOHnf80Wevl/PLHUUthCgaxqzs7vm43CUlVuttqtpCq5ORCque167kB/yU+yFg1YvaB/iC8mkEL24vkrCl6/s2kqhLj3WHLzNy6UEApj1RjwHNq1o4IiFEmZaRkt01f/vtqtg7bltld90n39Supp/8skjeWrq+Ran0aANfzlxLYlb4KSb/7xiezga61PX+9wOFEOJ+5HyH3LWAXw+1EJnqRliVkQ/X4IngSmQZVV5csp+hi/fyV4xMFSqE+O+SRC2siqIovPdkfZ4N9cdGp/DbyRi6zP2dt9YcufuDPIQQogyTRC2sjsFGz9s96rL5lTZ0CqpIllHluz/P0+6DbXy69a+7P8xDCCHKIEnUwmpVq+DMF8+EsGzYQ9Sv5EZiWiYfbIqiw6ztrDl4CaOxTI+DFEIIQBK1KAUeqlae/40IZU7fhvi62XPpVgphyyPp+dkf7P7nLtMdCiFEGSGJWpQKOp3CE8GV+e21dozrUhtngw2HL8bRd+GfDPt2H/9c+5dpNoUQopSSRC1KFXtbPSPa12Dra+0Y0NwPnQKbj1+l85wdTFl7jNikuzwJSgghSilJ1KJUquBiYNoT9dkU1ob2tSuQaVRZHHGWNh9sZeGOv0nLlAFnQoiyQRK1KNVqVnRh0bPN+O655tTxcSUhNZPp60/ScfZ21h2+TBmfeE8I8R8giVqUCa1qerJuVCvef6oBXi4GLtxMYeTSg/SaH8H+c7GWDk8IIe6bJGpRZuh1Cn1CqrBtXDvCOtbEwVbPwfO3eHJ+BCO+P8D5G8mWDlEIIQpNErUocxztbAjrWItt49rRJ6QyigK/HLlCx9nbmfbLceKSMywdohBCFJjVPz3r0qVLjB8/ng0bNpCSkkKtWrX46quvaNKkSYGOl6dniRNX4pm+/gS/n74OgJOdnmoVnKlUzoFK7g74lnOgUjkHKmevuzvaoljgQfJCiP+OMvP0rNjYWEJDQ2nfvj0bNmzAy8uLv//+m3Llylk6NFGK1PFx5duhzdh26hrTfznB6ZhEjlyK48iluHzrO9jq80ng9lQq54hvOXu8Xe2x0UtnlBCiZFh1op45cyZVqlRh0aJFpjJ/f3/LBSRKLUVRaF/bizY1KxAVncDF2GQu3Urh8q0ULt1K4VJsCpdupXI9MY2UjCz+iknkr5j8J1HR6xS8Xe2zk7f5Vbmrgy1K9vtpr6CgkHOBfvu22Tq5+7mtLOc8ep1COUdbnA02crUvxH+MVSfqtWvX0qVLF3r37s327dupVKkSw4cP54UXXrjrMWlpaaSl5T5lKSFBHpEocul1CkG+rgT5uua7PzUjiytxqdmJO5lLt3LXL99K5UpcChlZqpbcb6Wwl5IdUW5vq8PT2UAFFwMVnA14Zr9WcDGYyr2y1x3s9CUamxCieFh1ov7nn3+YP38+Y8eO5c0332TPnj2MHj0ag8HAM888k+8xM2bM4J133inhSEVZYW+rJ8DTiQBPp3z3ZxlVriemcTE2JfeKPDb3qjwpPZOcUR+qqqICqgoqavZrzj7gtrLb695+LNn7M41GUjO05WJsChdjU/71Z3E22ODpbKcl9ZxEfkdSr+BiwMXeBqNRe48so0qmUSXLqJKRZb6tvRrJyDLfzszezrhjO9Oootcp2Op12NnosNMr2a96bLPXbfU6DDY607pZmV6HTlew3oMso0pKRhbJ6Zkkp2WRnJ5FSkYmyenZ69mvyemZpKRnkZSeRUp69v6MnP3aPr1Oyf7AY4+XiwEvV4PZdnlnA/oCxiVEUbDqwWR2dnaEhIQQERFhKhs9ejR79+5l165d+R5z5xX1pUuXCAoKksFkotRLSc/iemIaMQlpXEtI43qi+eu1RG09Jj6NtEyjpcMtEnqdgp1el53Y9aZkr9cppGYYtcScnlWiP69OAQ8ngymJe2Un8ZzeDK1M27a3lV4Nkb8yM5jMx8eHoKAgs7I6deqwcuXKux5jMBgwGAym7fj4+GKLT4iS5GCnp4qHI1U8HO9ZT1VVEtMyuZ6YriXw25N5zvptST4jK/ezul6noNcp2Nz2aqPXmW1rr1qytNFr27Z3bNvoFHSKglGF9CwjGZlG0rOMpGcaych+Tb/tNWf/7bFA9pWyMYuUDIDMf20jRdEGAzra2eBop8fRTo9DzquteZmTnY1pn1Zmg6OtnowsI9eyP/DEJKRyLUH7cBSTkMaNxDSMKlzP/lB0/Mq943GxtzFL5OWd7XB3tMPdyQ53R1s8TOt2lHO0lcQu8mXViTo0NJSoqCizslOnTlG1alULRSSE9VMUBRd7W1zsbe/ahZ9DVVXSMo2mBGzpgWqqqpoSdnpmbmJPuyPBZ2aptyXgnGRrg72trlh/hiyjyo0kLYlrCfy2RB6vfQCKSUg19WokpGaSkJrJ39eSCnR+Rzs97o52eDhpidsjO4lrZbaUy2ff3ZJ7zu2LjOz2zGm/TGPues6+zKzcD0o5x+TUtbfVUd7JgIeTHZ7O2qudjXzroSRZdaJ+5ZVXaNmyJdOnT6dPnz7s2bOHhQsXsnDhQkuHJkSZoCiKVV3FKYqCwUaPwQYw/Gv1EqfXKdn3qu3vWU9VVeJTM82TeXwaN5PTuZWczs2kdGKTM4hNSic2WVvPMqrZ99G1MQ8F5WCrx9neRkvMpp4JI8ZivKnpYm9DeSc7yjsbsl/tTMk8Z728s7bu4WgnX2d8QFadqJs2bcrq1auZMGECU6dOJSAggLlz5zJgwABLhyaEEHelKApuDra4OdhSw8v5X+vnJPbcxJ1ObFIGsXck9dxEn8Gt5HQyswfRpWT8+9PibLIH9tnoc+7767C10cpsdbet67WBfDZ67RZHaoY2NuJmkhZLplE19RScLeC0vDk9AJ63J3Nn7Z6+t6s93m72eLka8HQyFHgA4X+JVQ8mKwoyM5kQoixSVZWENC25J6Zl3pZ8tcF3WvLNXS+KBKiqKvEpmVxPSuNGYjo3k9K4nqgl8BuJaVxPSudmYjo3knITe2Gu7G10Cl4uBiq62VPRRUvgFV3tqeiqJfSKbtqEQ04Gq77GLJAyM5hMCCFE/hRFwdXeFld72xJ9TzdHW9wcbale4d/rZxlVU1e/KaFnJ/mcAXtX41OJjtcmG8o0qlyOS+VyXOo9z+tssNGSd3ZCz0ngFV0NVHTVJiKq4GKw+JiLoiKJWgghRLHQ6xTtPrazgZoV7103I8vI9cQ0ouNSteQdl8rVhDSuxmmJPDpeG6SXmJapLdfuPUjPyU6Pf/acCNU8nQio4ESApzMB5Z1wcyy5DzdFQRK1EEIIi7PV6/Bxc8DHzeGe9RLTMomOSyUmPjeBX41L5Wp8mraevSSlZ3HscjzHLuf9iq6Hk51pYqPbE7l/eSerGlyZQxK1EEKIUsPZYEMNL+d7DtJLy8ziws0UzlxP4sz1RM5cT+Kfa0mcvZHE1fjc++f7z+WdAtjXzT776lu7Aq+WncwruztYbPS6JGohhBBlisFGf1syN+9zT0zL5Oz1pOwknsTZ60n8cz2Jf64lEp+aabpH/sdfN8yOs9Ep+Hk4Ur+yGx/1Cy7Bn0YStRBCiP8QZ4MN9Sq5Ua+Sm1m5qqrEJmdkX4En57kST80w8s/1JFzsSz5tSqIWQgjxn6coCh5Odng4edCkqofZPqNR5WpCKmeuJRXrRDJ3I4laCCGEuAedTinQQLdie3+LvKsQQgghCkQStRBCCGHFJFELIYQQVkwStRBCCGHFJFELIYQQVqzMj/o2Go0AXLlyxcKRCCGEEJqcnJSTo+6lzCfqq1evAtCsWTMLRyKEEEKYu3r1Kn5+fvesU+afR52ZmcnBgwepWLEiOt2D9fQnJCQQFBTE8ePHcXFxKaIIyzZps8KTNis8abPCkzYrvKJsM6PRyNWrVwkODsbG5t7XzGU+URel+Ph43NzciIuLw9XV1dLhlArSZoUnbVZ40maFJ21WeJZqMxlMJoQQQlgxSdRCCCGEFZNEXQgGg4G3334bg8Fg6VBKDWmzwpM2Kzxps8KTNis8S7WZ3KMWQgghrJhcUQshhBBWTBK1EEIIYcUkUQshhBBWTBJ1IXz22WcEBARgb29PkyZN+P333y0dktWaMWMGTZs2xcXFBS8vL3r27ElUVJSlwyo1ZsyYgaIohIWFWToUq3fp0iUGDhxI+fLlcXR0pFGjRuzfv9/SYVmlzMxM3nrrLQICAnBwcKBatWpMnTq1QNNY/lfs2LGDHj164Ovri6IorFmzxmy/qqpMmTIFX19fHBwcaNeuHceOHSvWmCRRF9Dy5csJCwtj4sSJHDx4kNatW9OtWzfOnz9v6dCs0vbt2xkxYgR//vkn4eHhZGZm0rlzZ5KSkiwdmtXbu3cvCxcupEGDBpYOxerFxsYSGhqKra0tGzZs4Pjx48yaNYty5cpZOjSrNHPmTBYsWMC8efM4ceIE77//Ph988AGffPKJpUOzGklJSTRs2JB58+blu//9999n9uzZzJs3j7179+Lt7U2nTp1ISEgovqBUUSDNmjVTX3rpJbOywMBA9Y033rBQRKVLTEyMCqjbt2+3dChWLSEhQa1Zs6YaHh6utm3bVh0zZoylQ7Jq48ePV1u1amXpMEqN7t27q0OHDjUr69Wrlzpw4EALRWTdAHX16tWmbaPRqHp7e6vvvfeeqSw1NVV1c3NTFyxYUGxxyBV1AaSnp7N//346d+5sVt65c2ciIiIsFFXpEhcXB4CHh4eFI7FuI0aMoHv37nTs2NHSoZQKa9euJSQkhN69e+Pl5UVwcDBffPGFpcOyWq1ateLXX3/l1KlTABw6dIidO3fyyCOPWDiy0uHMmTNER0eb5QKDwUDbtm2LNReU+adnFYXr16+TlZVFxYoVzcorVqxIdHS0haIqPVRVZezYsbRq1Yp69epZOhyrtWzZMg4cOMDevXstHUqp8c8//zB//nzGjh3Lm2++yZ49exg9ejQGg4FnnnnG0uFZnfHjxxMXF0dgYCB6vZ6srCymTZtG//79LR1aqZDz/31+ueDcuXPF9r6SqAtBURSzbVVV85SJvEaOHMnhw4fZuXOnpUOxWhcuXGDMmDFs3rwZe3t7S4dTahiNRkJCQpg+fToAwcHBHDt2jPnz50uizsfy5cv57rvvWLp0KXXr1iUyMpKwsDB8fX0ZPHiwpcMrNUo6F0iiLgBPT0/0en2eq+eYmJg8n6yEuVGjRrF27Vp27NhB5cqVLR2O1dq/fz8xMTE0adLEVJaVlcWOHTuYN28eaWlp6PV6C0ZonXx8fAgKCjIrq1OnDitXrrRQRNZt3LhxvPHGG/Tr1w+A+vXrc+7cOWbMmCGJugC8vb0B7crax8fHVF7cuUDuUReAnZ0dTZo0ITw83Kw8PDycli1bWigq66aqKiNHjmTVqlX89ttvBAQEWDokq9ahQweOHDlCZGSkaQkJCWHAgAFERkZKkr6L0NDQPF/7O3XqFFWrVrVQRNYtOTkZnc78v329Xi9fzyqggIAAvL29zXJBeno627dvL9ZcIFfUBTR27FgGDRpESEgILVq0YOHChZw/f56XXnrJ0qFZpREjRrB06VL+97//4eLiYuqNcHNzw8HBwcLRWR8XF5c89++dnJwoX7683Ne/h1deeYWWLVsyffp0+vTpw549e1i4cCELFy60dGhWqUePHkybNg0/Pz/q1q3LwYMHmT17NkOHDrV0aFYjMTGRv/76y7R95swZIiMj8fDwwM/Pj7CwMKZPn07NmjWpWbMm06dPx9HRkaeffrr4giq28eRl0KeffqpWrVpVtbOzUxs3bixfNboHIN9l0aJFlg6t1JCvZxXMzz//rNarV081GAxqYGCgunDhQkuHZLXi4+PVMWPGqH5+fqq9vb1arVo1deLEiWpaWpqlQ7MaW7duzff/rsGDB6uqqn1F6+2331a9vb1Vg8GgtmnTRj1y5EixxiRPzxJCCCGsmNyjFkIIIayYJGohhBDCikmiFkIIIayYJGohhBDCikmiFkIIIayYJGohhBDCikmiFkIIIayYJGohhBDCikmiFkIUOUVRWLNmjaXDEKJMkEQtRBkzZMgQFEXJs3Tt2tXSoQkh7oM8lEOIMqhr164sWrTIrMxgMFgoGiHEg5AraiHKIIPBgLe3t9ni7u4OaN3S8+fPp1u3bjg4OBAQEMCKFSvMjj9y5AgPP/wwDg4OlC9fnmHDhpGYmGhW5+uvv6Zu3boYDAZ8fHwYOXKk2f7r16/zxBNP4OjoSM2aNVm7dq1pX2xsLAMGDKBChQo4ODhQs2bNPB8shBAaSdRC/AdNmjSJJ598kkOHDjFw4ED69+/PiRMnAO2ZxV27dsXd3Z29e/eyYsUKtmzZYpaI58+fz4gRIxg2bBhHjhxh7dq11KhRw+w93nnnHfr06cPhw4d55JFHGDBgADdv3jS9//Hjx9mwYQMnTpxg/vz5eHp6llwDCFGaFOuzuYQQJW7w4MGqXq9XnZyczJapU6eqqqo9gvSll14yO6Z58+bqyy+/rKqqqi5cuFB1d3dXExMTTft/+eUXVafTqdHR0aqqqqqvr686ceLEu8YAqG+99ZZpOzExUVUURd2wYYOqqqrao0cP9dlnny2aH1iIMk7uUQtRBrVv35758+eblXl4eJjWW7RoYbavRYsWREZGAnDixAkaNmyIk5OTaX9oaChGo5GoqCgUReHy5ct06NDhnjE0aNDAtO7k5ISLiwsxMTEAvPzyyzz55JMcOHCAzp0707NnT1q2bHlfP6sQZZ0kaiHKICcnpzxd0f9GURQAVFU1redXx8HBoUDns7W1zXOs0WgEoFu3bpw7d45ffvmFLVu20KFDB0aMGMGHH35YqJiF+C+Qe9RC/Af9+eefebYDAwMBCAoKIjIykqSkJNP+P/74A51OR61atXBxccHf359ff/31gWKoUKECQ4YM4bvvvmPu3LksXLjwgc4nRFklV9RClEFpaWlER0ebldnY2JgGbK1YsYKQkBBatWrF999/z549e/jqq68AGDBgAG+//TaDBw9mypQpXLt2jVGjRjFo0CAqVqwIwJQpU3jppZfw8vKiW7duJCQk8McffzBq1KgCxTd58mSaNGlC3bp1SUtLY926ddSpU6cIW0CIskMStRBl0MaNG/Hx8TErq127NidPngS0EdnLli1j+PDheHt78/333xMUFASAo6MjmzZtYsyYMTRt2hRHR0eefPJJZs+ebTrX4MGDSU1NZc6cObz22mt4enry1FNPFTg+Ozs7JkyYwNmzZ3FwcKB169YsW7asCH5yIcoeRVVV1dJBCCFKjqIorF69mp49e1o6FCFEAcg9aiGEEMKKSaIWQgghrJjcoxbiP0budglRusgVtRBCCGHFJFELIYQQVkwStRBCCGHFJFELIYQQVkwStRBCCGHFJFELIYQQVkwStRBCCGHFJFELIYQQVkwStRBCCGHF/h/bGfMJLk6yqQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # 에포크에 대한 훈련 손실과 검증 손실의 그래프를 그립니다.\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # 처리한 토큰 수에 대한 두 번째 x 축을 만듭니다.\n",
        "    ax2 = ax1.twiny()  # y 축을 공유하는 두 번째 x 축을 만듭니다.\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 눈금을 정렬하기 위해 투명한 그래프를 만듭니다.\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
      "metadata": {
        "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995"
      },
      "source": [
        "- 위 결과를 보면 모델이 처음에는 이해할 수 없는 단어를 생성하지만 마지막으로 갈수록 문법적으로 어느 정도 정확한 문장을 생성합니다.\n",
        "- 하지만 훈련 세트 손실과 검증 세트 손실을 보면 모델이 과대적합되기 시작합니다.\n",
        "- 마지막 부분의 몇 문장을 확인하면 훈련 세트에 있는 내용이라는 것을 알 수 있습니다. 모델이 단순히 훈련 데이터를 암기한 것입니다.\n",
        "- 매우 작은 훈련 세트를 사용하고 모델을 여러 에포크에서 훈련하고 있기 때문에 과대적합이 일어납니다.\n",
        "  - 여기서는 교육적인 목적을 위해 LLM을 훈련합니다. 모델이 일관된 텍스트를 생성하는 방법을 학습할 수 있는지 확인하는 것이 주요 목적입니다.\n",
        "  - 대량의 고가 하드웨어에서 몇 주 또는 몇 달 동안 이런 모델을 훈련하는 대신에 나중에 사전 훈련된 가중치를 로드하여 사용하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
      "metadata": {
        "id": "eb380c42-b31c-4ee1-b8b9-244094537272"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/13.webp\" width=800px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
      "metadata": {
        "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c"
      },
      "source": [
        "- 더 큰 훈련 데이터셋에서 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
      "metadata": {
        "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
      },
      "source": [
        "## 5.3 무작위성을 제어하기 위한 디코딩 전략"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
      "metadata": {
        "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7"
      },
      "source": [
        "- 위에서 구현한 GPT 모델처럼 작은 LLM의 추론 비용은 비교적 저렴합니다. 따라서 훈련에 GPU를 사용했더라도 추론에서는 GPU를 사용할 필요가 없습니다.\n",
        "- 이전 장에서 만든 `generate_text_simple` 함수를 사용해 한 번에 하나의 단어(또는 토큰)씩 새로운 텍스트를 생성할 수 있습니다.\n",
        "- 5.1.2절에서 설명했듯이 생성된 다음 토큰은 어휘사전의 모든 토큰 중에서 확률 점수가 가장 높은 토큰입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
        "outputId": "f5080a0e-4445-471d-c7d8-151f68c2f099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "출력 텍스트:\n",
            " Every effort moves you,,,,,,,,,,,,,,,,,,, the,,,,,\n"
          ]
        }
      ],
      "source": [
        "# NEW: 이후 코드의 결과를 책과 일치하도록 만들기 위해 CPU를 사용합니다.\n",
        "inference_device = torch.device(\"cpu\")\n",
        "\n",
        "model.to(inference_device)\n",
        "model.eval()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
      "metadata": {
        "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4"
      },
      "source": [
        "- `generate_text_simple` 함수를 여러번 실행하더라도 LLM은 항상 동일한 출력을 생성합니다.\n",
        "- `generate_text_simple`를 수정하기 위해 두 가지 디코딩 전략을 소개합니다. *온도 스케일링*과 *탑-k* 샘플링입니다.\n",
        "- 이를 사용해 모델이 생성된 텍스트의 무작위성과 다양성을 조절할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
      "metadata": {
        "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994"
      },
      "source": [
        "### 5.3.1 온도 스케일링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
      "metadata": {
        "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa"
      },
      "source": [
        "- 이전에는 `torch.argmax`를 사용해 항상 가장 높은 확률을 가진 토큰을 다음 토큰으로 샘플링했습니다.\n",
        "- 다양성을 추가하기 위해 확률 분포에서 샘플링하도록 `torch.multinomial(probs, num_samples=1)`을 사용해 토큰을 샘플링할 수 있습니다.\n",
        "- 여기서 각 인덱스 선택 가능성은 입력 텐서에 있는 확률에 따라 결정됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
      "metadata": {
        "id": "e7531bae-d5de-44c0-bc78-78fed077e22a"
      },
      "source": [
        "- 여기에서 다음 토큰 생성에 대해 간략히 정리해 보겠습니다. 설명을 위해 매우 작은 어휘사전을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
        "outputId": "57b0d188-bea8-4a8a-dc3e-c54c10225b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "# 입력이 \"every effort moves you\"이고\n",
        "# LLM이 다음 토큰을 위해 아래와 같은 로짓을 반환했다고 가정해 보죠.\n",
        "next_token_logits = torch.tensor(\n",
        "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "\n",
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "\n",
        "# 생성될 토큰은 다음과 같습니다.\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
        "outputId": "c519d00d-f213-42e7-9c16-86a404fed916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
      "metadata": {
        "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9"
      },
      "source": [
        "- `torch.argmax`로 가장 가능성이 높은 토큰을 결정하는 대신에 `torch.multinomial(probas, num_samples=1)`를 사용해 소프트맥스 분포에서 샘플링하여 가장 가능성이 높은 토큰을 결정할 수 있습니다.\n",
        "- 설명을 위해 원래 소프트맥스 분포에서 1,000번 토큰을 샘플링해 보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
        "outputId": "e35f713c-1e4c-46ce-92f2-60bdd511a2e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "582 x forward\n",
            "2 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "343 x toward\n",
            "0 x you\n"
          ]
        }
      ],
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123) # 재현가능성을 위한 랜덤 시드\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
      "metadata": {
        "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832"
      },
      "source": [
        "- 온도 스케일링으로 분포와 선택 과정을 조절할 수 있습니다.\n",
        "- \"온도 스케일링\"은 로짓을 0보다 큰 숫자로 나누는 것을 의미합니다.\n",
        "- 1보다 큰 온도는 소프트맥스 함수를 적용한 후에 더 균등한 토큰 확률 분포를 만듭니다.\n",
        "- 1보다 작은 온도는 소프트맥스 함수를 적용한 후에 더 결정론적인 분포(더 날카롭거나 뾰족한 분포)를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
      "metadata": {
        "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d"
      },
      "outputs": [],
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    scaled_logits = logits / temperature\n",
        "    return torch.softmax(scaled_logits, dim=0)\n",
        "\n",
        "# 온도 값\n",
        "temperatures = [1, 0.1, 5]  # 원본, 낮은 온도, 높은 온도\n",
        "\n",
        "# 스케일을 조정한 확률 계산\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
        "outputId": "a0b3394f-05e2-473d-e51e-1d88c3354538"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 그래프 그리기\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"temperature-plot.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
      "metadata": {
        "id": "d750e989-842a-4cfa-a44b-cf44d6e49163"
      },
      "source": [
        "- 온도 0.1로 스케일을 조정하면 더 뾰족한 분포를 만들어, `torch.argmax`에 가까워져 항상 가장 가능성있는 토큰이 선택됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
        "outputId": "23b31ef9-3a32-4926-a808-91036e0b07e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "985 x forward\n",
            "0 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "15 x toward\n",
            "0 x you\n"
          ]
        }
      ],
      "source": [
        "print_sampled_tokens(scaled_probas[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
      "metadata": {
        "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b"
      },
      "source": [
        "- 온도 5로 스케일을 조정한 확률은 더 균등한 분포가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
        "outputId": "88ee1ea5-8c83-4180-c203-174ad6b8cb42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "165 x closer\n",
            "75 x every\n",
            "42 x effort\n",
            "239 x forward\n",
            "71 x inches\n",
            "46 x moves\n",
            "32 x pizza\n",
            "227 x toward\n",
            "103 x you\n"
          ]
        }
      ],
      "source": [
        "print_sampled_tokens(scaled_probas[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
      "metadata": {
        "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7"
      },
      "source": [
        "- LLM 입력이 \"every effort moves you\"일 경우 위와 같은 방법을 사용하면 \"every effort moves you pizza\"와 같이 3.2%의 확률(1,000번 중에 32번)로 이따금 말이 안되는 텍스트를 생성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
      "metadata": {
        "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7"
      },
      "source": [
        "### 5.3.2 탑-k 샘플링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
      "metadata": {
        "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df"
      },
      "source": [
        "- 높은 온도를 사용하여 출력의 다양성을 증가시키면서 말이 안되는 문장이 생성될 가능성을 낮추기 위해 가장 가능성있는 상위 k개 토큰으로 샘플링될 토큰을 제한할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
      "metadata": {
        "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/15.webp\" width=700px>\n",
        "\n",
        "- (이 그림의 숫자는 간단하게 나타내려고 소숫점 두자리 이후를 자른 값입니다. 소프트맥스 열의 값은 모두 더해서 1.0이 되어야 합니다)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
      "metadata": {
        "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c"
      },
      "source": [
        "- 코드로는 다음과 같이 구현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
        "outputId": "32c685f3-3367-4b14-cb6d-f9851605a23a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "탑-k 로짓: tensor([6.7500, 6.2800, 4.5100])\n",
            "탑-k 위치: tensor([3, 7, 0])\n"
          ]
        }
      ],
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "print(\"탑-k 로짓:\", top_logits)\n",
        "print(\"탑-k 위치:\", top_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
        "outputId": "112ab5bf-a106-41bd-ac32-5e2ad345e242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ],
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    input=torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "\n",
        "print(new_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
      "metadata": {
        "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00"
      },
      "source": [
        "> 노트:  \n",
        ">\n",
        ">  이전 코드를 조금 더 효율적으로 구현하는 방법은 다음과 같습니다.\n",
        ">\n",
        "> ```python\n",
        "> new_logits = torch.full_like( # -inf 값을 담은 텐서를 만듭니다.\n",
        ">    next_token_logits, -torch.inf\n",
        ">)   \n",
        "> new_logits[top_pos] = next_token_logits[top_pos] # -inf 텐서에 상위 k개 값을 복사합니다.\n",
        "> ```\n",
        "> <br>\n",
        "> 자세한 내용은 다음을 참고하세요: https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
        "outputId": "46ff7a1f-e250-4987-a727-60427dce7163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
      "metadata": {
        "id": "56056503-a15d-4315-a3ff-46647a4c7c45"
      },
      "source": [
        "### 5.3.3 텍스트 생성 함수 수정하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34770423-473d-46f6-a5fa-6b2979564d26",
      "metadata": {
        "id": "34770423-473d-46f6-a5fa-6b2979564d26"
      },
      "source": [
        "- 이전 두 개의 절에서 온도 스케일링과 탑-k 샘플링을 소개했습니다.\n",
        "- 두 개념을 사용해 앞서 LLM으로 텍스트를 생성할 때 사용한 `generate_sample` 함수를 수정해 새로운 `generate` 함수를 만들어 보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
      "metadata": {
        "id": "8e318891-bcc0-4d71-b147-33ce55febfa3"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # for 루프는 이전과 동일합니다. 로짓을 받아 마지막 타임 스텝만 사용합니다.\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # 탑-k 샘플링으로 로짓을 필터링합니다.\n",
        "        if top_k is not None:\n",
        "            # 탑-k 값만 유지합니다.\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # 온도 스케일링을 적용합니다.\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # (책에 없음): mps 장치에서 동일한 결과를 얻기 위해 수치 안정성을 위한 팁\n",
        "            # 소프트맥스 전에 행의 최댓값을 뺍니다.\n",
        "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
        "\n",
        "            # 소프트맥스 함수를 적용하여 확률을 얻습니다.\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # 분포에서 샘플링합니다.\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # 온도 스케일링을 사용하지 않는 경우 이전처럼 그리디 샘플링을 사용해 다음 토큰을 선택합니다.\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # eos_id가 지정되어 있고 EoS 토큰을 만나면 생성을 중단합니다.\n",
        "            break\n",
        "\n",
        "        # 이전과 동일하게 샘플링된 인덱스를 현재 시퀀스 뒤에 추가합니다.\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
        "outputId": "e6245157-adce-45a5-ba67-7d12a231c42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "출력 텍스트:\n",
            " Every effort moves you, I.\" I it a,. his that \" my a \" had\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
      "metadata": {
        "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b"
      },
      "source": [
        "## 5.4 파이토치로 모델 로드하고 저장하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fc52676-f026-4566-a226-2a90269f9d53",
      "metadata": {
        "id": "0fc52676-f026-4566-a226-2a90269f9d53"
      },
      "source": [
        "- LLM 훈련에는 계산 비용이 많이 듭니다. 따라서 LLM 가중치를 저장하고 로드하는 것이 중요합니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/16.webp\" width=800px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
      "metadata": {
        "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82"
      },
      "source": [
        "- 파이토치에서는 `torch.save` 함수를 `.state_dict()` 메서드 결과에 적용해 소위 `state_dict`인 모델 가중치를 저장하는 것이 권장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
      "metadata": {
        "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
      "metadata": {
        "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e"
      },
      "source": [
        "- 그다음 모델 가중치를 새로운 `GPTModel` 클래스 인스턴스에 로드할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
      "metadata": {
        "id": "9d57d914-60a3-47f1-b499-5352f4c457cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
      "metadata": {
        "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1"
      },
      "source": [
        "- 일반적인 SGD 대신 Adam이나 AdamW와 같이 적응형 옵티마이저로 LLM을 훈련하는 것이 일반적입니다.\n",
        "- 이런 적응형 옵티마이저는 모델 가중치마다 추가적인 파라미터를 저장합니다. 나중에 사전 훈련을 계속하려면 이 파라미터도 저장하는 것이 맞습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
      "metadata": {
        "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "8a0c7295-c822-43bf-9286-c45abc542868",
      "metadata": {
        "id": "8a0c7295-c822-43bf-9286-c45abc542868"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4194350e-0409-4a63-8ffd-d3a896509032",
      "metadata": {
        "id": "4194350e-0409-4a63-8ffd-d3a896509032"
      },
      "source": [
        "## 5.5 오픈AI에서 사전 훈련된 가중치 로드하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
      "metadata": {
        "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec"
      },
      "source": [
        "- 앞서 하나의 단편 소설로 구성된 작은 데이터셋을 사용해 소규모 GPT-2 모델을 훈련했습니다.\n",
        "- 구텐베르크 프로젝트에 있는 전체 책으로 더 오래 모델을 훈련하고 싶다면 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)을 참고하세요.\n",
        "- 다행히 오픈AI는 GPT-2 모델의 가중치를 공개적으로 제공하기 때문에 대규모 말뭉치에서 모델을 재훈련하기 위해 수만에서 수십만 달러를 쓸 필요가 없습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
      "metadata": {
        "id": "127ddbdb-3878-4669-9a39-d231fbdfb834"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "⚠️ **노트: 일부 사용자는 특히 윈도 운영체제에서 텐서플로의 호환성 때문에 문제가 발생할 수 있습니다. 원본 OpenAI GPT-2 가중치 파일을 로드하기 위해 텐서플로가 필요하며 그다음 파이토치로 변환합니다.\n",
        "텐서플로 관련 이슈가 발생한다면 이 절의 남은 코드를 실행하는 대신 아래 코드를 사용할 수 있습니다.\n",
        "아래 코드는 이전 절에 설명된 변환 과정을 사용해 미리 파이토치용으로 바꾼 가중치를 사용합니다. 자세한 내용은 다음 노트북을 참고하세요. [../02_alternative_weight_loading/weight-loading-pytorch.ipynb](../02_alternative_weight_loading/weight-loading-pytorch.ipynb).**\n",
        "\n",
        "```python\n",
        "file_name = \"gpt2-small-124M.pth\"\n",
        "# file_name = \"gpt2-medium-355M.pth\"\n",
        "# file_name = \"gpt2-large-774M.pth\"\n",
        "# file_name = \"gpt2-xl-1558M.pth\"\n",
        "\n",
        "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    urllib.request.urlretrieve(url, file_name)\n",
        "    print(f\"다운로드 파일: {file_name}\")\n",
        "\n",
        "gpt = GPTModel(BASE_CONFIG)\n",
        "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
        "gpt.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gpt.to(device);\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75cab892-a165-4f43-9601-f517bc212ab6",
      "metadata": {
        "id": "75cab892-a165-4f43-9601-f517bc212ab6"
      },
      "source": [
        "- 먼저 OpenAI에서 파일을 다운로드하고 파이썬으로 가중치를 로드하는 코드가 필요합니다.\n",
        "- OpenAI가 [텐서플로](https://www.tensorflow.org/)를 사용했기 때문에 가중치를 로드하기 위해 텐서플로를 설치하고 사용해야 합니다. [tqdm](https://github.com/tqdm/tqdm)은 진행 표시줄을 나타내기 위한 라이브러리입니다.\n",
        "- 필요한 라이브러리를 설치하려면 다음 코드의 주석을 제거하고 실행하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
      "metadata": {
        "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
        "outputId": "de95758b-68b8-4f7d-cec5-2ff74a38e41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "텐서플로 버전: 2.19.1\n",
            "tqdm 버전: 4.67.1\n"
          ]
        }
      ],
      "source": [
        "print(\"텐서플로 버전:\", version(\"tensorflow\"))\n",
        "print(\"tqdm 버전:\", version(\"tqdm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dvJjVQPWpg6B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvJjVQPWpg6B",
        "outputId": "8dc7fbf3-197f-4cab-a59b-1ccff40a4746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-10-23 03:13:11--  https://bit.ly/4kSEn1v\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_download.py [following]\n",
            "--2025-10-23 03:13:11--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6333 (6.2K) [text/plain]\n",
            "Saving to: ‘gpt_download.py’\n",
            "\n",
            "gpt_download.py     100%[===================>]   6.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-23 03:13:11 (89.8 MB/s) - ‘gpt_download.py’ saved [6333/6333]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 깃허브에서 gpt_download.py 파일을 다운로드합니다.\n",
        "!wget https://bit.ly/4kSEn1v -O gpt_download.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
      "metadata": {
        "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed"
      },
      "outputs": [],
      "source": [
        "from gpt_download import download_and_load_gpt2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
      "metadata": {
        "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc"
      },
      "source": [
        "---\n",
        "\n",
        "**노트**\n",
        "\n",
        "- 드물게 텐서플로 설치 이슈 때문에 위 코드 셀에서 `zsh: illegal hardware instruction python` 오류가 발생할 수 있습니다.\n",
        "- 이 문제를 해결하기 위해 `conda`를 사용해 텐서플로를 설치하는 방법은 [깃허브 이슈](https://github.com/rasbt/LLMs-from-scratch/discussions/273#discussioncomment-12367888)를 참고하세요.\n",
        "- conda 사용에 관한 추가적인 내용은 [Python setup tutorial](https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences#option-2-using-conda)을 참고하세요.\n",
        "\n",
        "---\n",
        "\n",
        "- 다음처럼 1억 2,400만 파라미터를 가진 모델의 가중치를 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
        "outputId": "85f10d71-8dec-4890-b977-2edba8ff738e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 145kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 622kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 229kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [03:26<00:00, 2.41MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 13.5MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 379kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 457kiB/s]\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
        "outputId": "0476373c-3434-4924-bf8f-ca32a5da1d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "설정: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
          ]
        }
      ],
      "source": [
        "print(\"설정:\", settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
        "outputId": "26d3afff-6f13-4a22-d72a-f9208c574fa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파라미터 딕셔너리 키: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ],
      "source": [
        "print(\"파라미터 딕셔너리 키:\", params.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
        "outputId": "be90a95f-7d18-44d2-fc69-762aaef0ec42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "토큰 임베딩 가중치 텐서의 차원: (50257, 768)\n"
          ]
        }
      ],
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"토큰 임베딩 가중치 텐서의 차원:\", params[\"wte\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
      "metadata": {
        "id": "466e100c-294e-4afc-a70a-2f398ac4c104"
      },
      "source": [
        "- `model_size` 매개변수에 \"355M\", \"774M\", \"1558M\"도 지정할 수 있습니다.\n",
        "- 이런 모델의 차이점은 다음 그림에 요약되어 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
      "metadata": {
        "id": "20f19d32-5aae-4176-9f86-f391672c8f0d"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/17.webp\" width=700px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
      "metadata": {
        "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41"
      },
      "source": [
        "- 위에서 1억 2,400만 파라미터의 GPT-2 모델 가중치를 파이썬으로 로드했습니다. 이제 `GPTModel` 클래스의 인스턴스로 복사해야 합니다.\n",
        "- 먼저, 새로운 `GPTModel` 인스턴스를 초기화합니다.\n",
        "- 원본 GPT 모델은 멀티 헤드 어텐션 모듈의 쿼리, 키, 값 행렬을 위한 선형 층에서 편향 벡터를 사용합니다. 이것이 필수적이지는 않지만 사전 훈련된 가중치를 제대로 로드하기 위해서 `qkv_bias`를 `True`로 설정해야 합니다.\n",
        "- 또한 원본 GPT-2 모델에서 사용한 문맥 크기인 `1024` 토큰을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
      "metadata": {
        "id": "9fef90dd-0654-4667-844f-08e28339ef7d"
      },
      "outputs": [],
      "source": [
        "# 딕셔너리로 모델 설정을 저장합니다.\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# 기본 설정을 특정 값으로 업데이트합니다.\n",
        "model_name = \"gpt2-small (124M)\"  # 모델 이름\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
      "metadata": {
        "id": "272f29ac-8342-4b3d-a57d-9b0166ced314"
      },
      "source": [
        "- 다음 작업은 OpenAI 가중치를 `GPTModel` 인스턴스에 있는 가중치 텐서에 할당하는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
      "metadata": {
        "id": "f9a92229-c002-49a6-8cfb-248297ad8296"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"크기가 다릅니다. left: {left.shape}, right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
      "metadata": {
        "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
      "metadata": {
        "id": "4f7472cb-54dc-4311-96d8-b2694f885cee"
      },
      "source": [
        "- 모델이 올바르게 로드되었다면 `generate` 함수를 사용해 새로운 텍스트를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
        "outputId": "822f6c4c-6a8f-48e3-a685-55f221edffab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "출력 텍스트:\n",
            " Every effort moves you as far as the hand can go until the end of your turn unless something happens\n",
            "\n",
            "This would remove you from a battle\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"출력 텍스트:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
      "metadata": {
        "id": "6d079f98-a7c4-462e-8416-5a64f670861c"
      },
      "source": [
        "- 모델이 일관성 있는 텍스트를 생성했기 때문에 가중치가 올바르게 로드되었다고 확신할 수 있습니다. 이 과정에서 조금만 잘못되어도 모델이 제대로 텍스트를 생성하지 못합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
      "metadata": {
        "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44"
      },
      "source": [
        "- 허깅 페이스 허브에서 가중치를 로드하는 방법은 [../02_alternative_weight_loading](../02_alternative_weight_loading)에 있는 노트북을 참고하세요.\n",
        "- GPT 구조와 (메타에서 개발한) Llama 구조를 비교해 보려면 보너스 콘텐츠 [../07_gpt_to_llama](../07_gpt_to_llama)를 참고하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
      "metadata": {
        "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4"
      },
      "source": [
        "## 요약"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
      "metadata": {
        "id": "fc7ed189-a633-458c-bf12-4f70b42684b8"
      },
      "source": [
        "- [./gpt_train.py](./gpt_train.py)는 훈련 스크립트 파일입니다.\n",
        "- [./gpt_generate.py](./gpt_generate.py)는 OpenAI에서 사전 훈련된 가중치를 로드하여 프롬프트를 기반으로 텍스트를 생성합니다.\n",
        "- 연습문제 솔루션은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에 있습니다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
