{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true,
    "id": "WTjKfTWE-XAX",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 가상 데이터셋 생성\n",
    "num_samples = 1000\n",
    "num_classes = 10\n",
    "input_shape = (28, 28)\n",
    "\n",
    "x_train = np.random.random((num_samples, *input_shape)).astype(np.float32)\n",
    "y_train = np.random.randint(num_classes, size=num_samples).astype(np.int64)\n",
    "x_test = np.random.random((num_samples // 5, *input_shape)).astype(np.float32)\n",
    "y_test = np.random.randint(num_classes, size=num_samples // 5).astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 28, 28), (1000,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 28, 28), (200,))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1,2,3])\n",
    "ut = t.unsqueeze(0)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1,2,3])\n",
    "ut = t.unsqueeze(1)  # (3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서로 변환\n",
    "x_train = torch.tensor(x_train).unsqueeze(1)\n",
    "y_train = torch.tensor(y_train)\n",
    "x_test = torch.tensor(x_test).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # [batch_size, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB 컬러 이미지 (1000, 28, 28, 3)\n",
    "# x_train = torch.tensor(x_train).permute(0, 3, 1, 2)\n",
    "# 결과: (1000, 3, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터 로더 생성\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "2dO-OCcg-Zo7"
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "_1Z1lPEN-dfD"
   },
   "outputs": [],
   "source": [
    "# SGD 옵티마이저 선택 및 학습률 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "Gk0mqCiW-ra_"
   },
   "outputs": [],
   "source": [
    "# 손실 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `criterion = nn.CrossEntropyLoss()`\n",
    "\n",
    "### **Definition**\n",
    "\n",
    "`nn.CrossEntropyLoss` is a **loss function** used for **multi-class classification** problems in PyTorch.\n",
    "It combines two key operations into one:\n",
    "\n",
    "$\n",
    "\\text{CrossEntropyLoss} = \\text{LogSoftmax} + \\text{Negative Log Likelihood (NLLLoss)}\n",
    "$\n",
    "\n",
    "So, you don’t need to apply `softmax` manually to your model’s outputs — `CrossEntropyLoss` handles that internally.\n",
    "\n",
    "---\n",
    "\n",
    "### **Mathematical Formula**\n",
    "\n",
    "For a single input sample:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = -\\log\\left( \\frac{e^{z_{y}}}{\\sum_{j} e^{z_j}} \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $z_j$ = raw (unnormalized) output score (logit) from the network for class ( j )\n",
    "* $y$ = correct class index\n",
    "* The numerator is the exponential of the true class logit.\n",
    "* The denominator sums over all class logits, normalizing them via the softmax.\n",
    "\n",
    "---\n",
    "\n",
    "### **Intuition**\n",
    "\n",
    "* Your model outputs a vector of raw scores, e.g. `[2.1, -1.3, 0.7]`.\n",
    "* `CrossEntropyLoss` first applies **softmax** to turn these scores into probabilities.\n",
    "* Then it computes how far the predicted distribution is from the **true label** (which is treated as a one-hot vector).\n",
    "\n",
    "It penalizes the model when:\n",
    "\n",
    "* The correct class gets **low probability**.\n",
    "* Other classes get **high probability**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Usage Example**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Example logits (2 samples, 3 classes each)\n",
    "outputs = torch.tensor([[2.5, 0.3, -1.2],\n",
    "                        [0.1, 2.0, 0.1]])  # shape: [batch_size, num_classes]\n",
    "\n",
    "# True class indices\n",
    "labels = torch.tensor([0, 1])  # shape: [batch_size]\n",
    "\n",
    "loss = criterion(outputs, labels)\n",
    "print(loss)\n",
    "```\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "* `outputs` = raw logits (no softmax applied)\n",
    "* `labels` = integer indices (not one-hot vectors)\n",
    "* The loss is **averaged** across the batch by default.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1944)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Example logits (2 samples, 3 classes each)\n",
    "outputs  = torch.tensor([[2.5, 0.3, -1.2],\n",
    "                        [0.1, 2.0, 0.1]])  # shape: [batch_size, num_classes]\n",
    "\n",
    "# True class indices\n",
    "labels = torch.tensor([0, 1])  # shape: [batch_size]\n",
    "\n",
    "loss = criterion(outputs , labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rv_36TjR-s3G",
    "outputId": "54571dcc-f792-4777-cedf-10283cf92e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.286495864391327\n",
      "Epoch 2, Loss: 2.2782506942749023\n",
      "Epoch 3, Loss: 2.273959696292877\n",
      "Epoch 4, Loss: 2.270854525268078\n",
      "Epoch 5, Loss: 2.256908133625984\n",
      "Epoch 6, Loss: 2.250021517276764\n",
      "Epoch 7, Loss: 2.2568142488598824\n",
      "Epoch 8, Loss: 2.222443498671055\n",
      "Epoch 9, Loss: 2.2075348272919655\n",
      "Epoch 10, Loss: 2.1897913962602615\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPc-nvFr-uwT",
    "outputId": "b43bb2dc-6396-4be7-bb44-c16328812032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 12.00%\n",
      "Test Loss: 2.1898\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "loss = running_loss / len(train_loader)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Test Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vq0hSia7-wRx",
    "outputId": "ad9affb4-710e-4e4a-db1a-863350dd8f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1705394834280014\n",
      "Epoch 2, Loss: 2.1494657322764397\n",
      "Epoch 3, Loss: 2.132377963513136\n",
      "Epoch 4, Loss: 2.110610753297806\n",
      "Epoch 5, Loss: 2.103687711060047\n",
      "Epoch 6, Loss: 2.087603021413088\n",
      "Epoch 7, Loss: 2.0774229615926743\n",
      "Epoch 8, Loss: 2.0598913617432117\n",
      "Epoch 9, Loss: 2.052796706557274\n",
      "Epoch 10, Loss: 2.0338753163814545\n",
      "Test Accuracy: 8.00%\n",
      "Test Loss: 2.0339\n"
     ]
    }
   ],
   "source": [
    "# Adam 옵티마이저 사용 예시\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "loss = running_loss / len(train_loader)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Test Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
