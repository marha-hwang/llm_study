{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# A100 GPU ìµœì í™” ì„¤ì •\n",
    "torch.backends.cudnn.benchmark = True  # ìµœì ì˜ ì•Œê³ ë¦¬ì¦˜ ìë™ ì„ íƒ\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  # TF32 í™œì„±í™” (A100 íŠ¹í™”)\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "\n",
    "\n",
    "def get_CIFAR10_data_loader(ratio:int = 1.0)-> tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    CIFAR10ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì „ì²´ í›ˆë ¨ì…‹ : 50000ê°œ, ì „ì²´ í…ŒìŠ¤íŠ¸ì…‹ : 10000ê°œ)\n",
    "\n",
    "    Args:\n",
    "        ratio: ì „ì²´ ë°ì´í„°ì…‹ ëŒ€ë¹„ ë¹„ì¤‘\n",
    "\n",
    "    Returns:\n",
    "        (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    TRAINSET_COUNT = 50000\n",
    "\n",
    "    # 1. ì „ì²˜ë¦¬ ì •ì˜ (GPU ì¹œí™”ì )\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),  # ë°ì´í„° ì¦ê°•\n",
    "        transforms.RandomCrop(224, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train\n",
    "    )\n",
    "\n",
    "    # ë°ì´í„° ì„œë¸Œì…‹ ìƒì„±\n",
    "    indices = list(range(int(TRAINSET_COUNT * ratio)))\n",
    "    subset_trainset = Subset(trainset, indices)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_test\n",
    "    )\n",
    "\n",
    "    # 3. DataLoader ìƒì„± (A100 ìµœì í™”)\n",
    "    # A100ì€ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        subset_trainset,\n",
    "        batch_size=64,  # A100ì— ìµœì í™”ëœ í° ë°°ì¹˜ ì‚¬ì´ì¦ˆ\n",
    "        shuffle=True,\n",
    "        num_workers=12,  # A100 ì‹œìŠ¤í…œì˜ CPU ì½”ì–´ í™œìš©\n",
    "        pin_memory=True,  # GPU ì „ì†¡ ì†ë„ í–¥ìƒ\n",
    "        prefetch_factor=4,  # ë¯¸ë¦¬ ê°€ì ¸ì˜¬ ë°°ì¹˜ ìˆ˜\n",
    "        persistent_workers=True  # Worker ì¬ì‚¬ìš©\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=512,  # í‰ê°€ ì‹œ ë” í° ë°°ì¹˜\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "def get_custom_resnet50(class_count:int = 10) -> models.ResNet:\n",
    "    \"\"\"\n",
    "    resnetì˜ ë¶„ë¥˜í´ë˜ìŠ¤ë¥¼ ë³€ê²½í•˜ì—¬ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        í´ë˜ìŠ¤ì˜ ê°œìˆ˜\n",
    "\n",
    "    Returns:\n",
    "        ResNetëª¨ë¸\n",
    "    \"\"\"\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    # ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ì™„ì „ì—°ê²°ì¸µ ë ˆì´ì–´ ë³€ê²½\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, class_count)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_custom_vgg16(class_count:int = 10) -> models.vgg16:\n",
    "    \"\"\"\n",
    "    VGG16ì˜ ë¶„ë¥˜í´ë˜ìŠ¤ë¥¼ ë³€ê²½í•˜ì—¬ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        í´ë˜ìŠ¤ì˜ ê°œìˆ˜\n",
    "\n",
    "    Returns:\n",
    "        VGG16ëª¨ë¸\n",
    "    \"\"\"\n",
    "    model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "    in_features = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(in_features, 10)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, loss_function, test_loader, device):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        model : í…ŒìŠ¤íŠ¸ ëª¨ë¸,\n",
    "        loss_function : ì†ì‹¤í•¨ìˆ˜\n",
    "        test_loader : í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹,\n",
    "        device : í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ë””ë°”ì´ìŠ¤\n",
    "\n",
    "    Returns:\n",
    "        í•™ìŠµ ì˜¤ì°¨ìœ¨, ì •í™•ë„(%)\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval() # ğŸ‘ˆ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # ğŸ‘ˆ ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”\n",
    "        running_loss = 0.0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    return (running_loss, accuracy)\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, loss_function, train_loader, test_loader, device):\n",
    "  \"\"\"\n",
    "  ëª¨ë¸ì„ í›ˆë ¨ í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "  Args:\n",
    "      model : í…ŒìŠ¤íŠ¸ ëª¨ë¸,\n",
    "      optimizer : ì˜µí‹°ë§ˆì´ì €,\n",
    "      loss_function : ì†ì‹¤í•¨ìˆ˜,\n",
    "      train_loader : í›ˆë ¨ ë°ì´í„°ì…‹\n",
    "      test_loader : í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹,\n",
    "      device : í›ˆë ¨ì„ ìˆ˜í–‰í•  ë””ë°”ì´ìŠ¤\n",
    "\n",
    "  Returns:\n",
    "      list : ê° ì—í¬í¬ë§ˆë‹¤ í•™ìŠµ ì˜¤ì°¨ìœ¨, ì •í™•ë„(%)\n",
    "  \"\"\"\n",
    "\n",
    "  model.to(device)\n",
    "\n",
    "  print(\"Starting Training...\")\n",
    "  num_epochs = 5  # ğŸ‘ˆ ì „ì²´ ë°ì´í„°ì…‹ì„ 5ë²ˆ ë°˜ë³µ í•™ìŠµ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n",
    "  result = []\n",
    "  for epoch in range(num_epochs):\n",
    "      # Dropout, BatchNorm ë“±ì´ í•™ìŠµ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.\n",
    "      model.train()\n",
    "\n",
    "      # train_loaderì—ì„œ ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "      for i, (images, labels) in enumerate(train_loader):\n",
    "          # 1. ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "          images = images.to(device, non_blocking=True)\n",
    "          labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "          # 2. (í•„ìˆ˜) ì˜µí‹°ë§ˆì´ì €ì˜ ê¸°ìš¸ê¸°(gradient)ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”\n",
    "          optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "          # 3. ìˆœì „íŒŒ(Forward pass): ëª¨ë¸ì— ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•˜ì—¬ ì¶œë ¥(ë¡œì§“) ê³„ì‚°\n",
    "          outputs = model(images)\n",
    "\n",
    "          # 4. ì†ì‹¤(Loss) ê³„ì‚°\n",
    "          loss = loss_function(outputs, labels)\n",
    "\n",
    "          # 5. (í•„ìˆ˜) ì—­ì „íŒŒ(Backward pass): ì†ì‹¤ì— ëŒ€í•œ ê¸°ìš¸ê¸° ê³„ì‚°\n",
    "          loss.backward()\n",
    "\n",
    "          # 6. (í•„ìˆ˜) ì˜µí‹°ë§ˆì´ì € ì‹¤í–‰: ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "          optimizer.step()\n",
    "\n",
    "      # --- í•œ Epochì´ ëë‚  ë•Œë§ˆë‹¤ í…ŒìŠ¤íŠ¸ ì •í™•ë„ í‰ê°€ ---\n",
    "      epoch_loss, epoch_accuracy = test_model(model, loss_function, test_loader, device)\n",
    "      result.append((epoch_loss, epoch_accuracy))\n",
    "      print(f\"ì—í¬í¬ {epoch+1} í•™ìŠµ ì™„ë£Œ, ì •í™•ë„ : {epoch_accuracy}, ì†ì‹¤ : {epoch_loss}\")\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def make_loss_accuracy_graph(losses:list[tuple[str, list[float]]], accrucies:list[tuple[str, float]]):\n",
    "    \"\"\"\n",
    "    ì†ì‹¤, ì •í™•ë„ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ì£¼ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        losses : (í›ˆë ¨ì¡°ê±´, í›ˆë ¨ê²°ê³¼) ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸\n",
    "        accrucies : (í›ˆë ¨ì¡°ê±´, í›ˆë ¨ê²°ê³¼) ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    Returns:\n",
    "        ì—†ìŒ\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "    # ì†ì‹¤ê·¸ë˜í”„ ìƒì„±\n",
    "    for loss in losses:\n",
    "        label, values = loss\n",
    "        axes[0].plot([i for i in range (1, len(values)+1)], values, label=label)\n",
    "\n",
    "    axes[0].set_title(\"loss graph\")\n",
    "    axes[0].set_xlabel(\"epoch\")\n",
    "    axes[0].set_ylabel(\"loss\")\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[0].legend()\n",
    "\n",
    "\n",
    "    # ì •í™•ë„ ê·¸ë˜í”„ ìƒì„±\n",
    "    for accuracy in accrucies:\n",
    "        label, values = accuracy\n",
    "        axes[1].plot([i for i in range (1, len(values)+1)], values, label=label)\n",
    "\n",
    "    axes[1].set_title(\"accuracy graph\")\n",
    "    axes[1].set_xlabel(\"epoch\")\n",
    "    axes[1].set_ylabel(\"accuracy(%)\")\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.tight_layout() # ì„œë¸Œí”Œë¡¯ë“¤ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ê°„ê²©ì¡°ì ˆ\n",
    "    plt.show()\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¶œë ¥í•˜ê¸°\n",
    "def print_img(data, label):\n",
    "    img_grid = data * 0.5 + 0.5\n",
    "    np_grid = img_grid.numpy()\n",
    "    np_grid_rgb = np.transpose(np_grid,(1,2,0)) # ê¸°ì¡´ (ì±„ë„, ë†’ì´, ë„ˆë¹„) -> (ë†’ì´, ë„ˆë¹„, ì±„ë„)\n",
    "\n",
    "    print(label)\n",
    "\n",
    "    plt.figure(figsize=(10, 2)) # ê°€ë¡œ 10, ì„¸ë¡œ 2 ì¸ì¹˜\n",
    "    plt.imshow(np_grid_rgb)\n",
    "    plt.axis('off') # ì¶• ì •ë³´ ë„ê¸°\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97400b0f",
   "metadata": {},
   "source": [
    "1. ì‚¬ì „ í›ˆë ¨ëœ ResNet ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ìƒˆë¡œìš´ ì´ë¯¸ì§€ ë°ì´í„°ì…‹(ì˜ˆ: CIFAR-10, ê°„ë‹¨í•œ custom dataset)ì„ ë¶„ë¥˜í•˜ì„¸ìš”.\n",
    "1-1. í•™ìŠµ ì—†ì´ ë°”ë¡œ inferenceë¥¼ ì‹¤í–‰í•œ ë’¤ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³ , ì¶”ê°€ í•™ìŠµ(fine-tuning)ì„ ìˆ˜í–‰í–ˆì„ ë•Œ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¹„êµí•˜ì„¸ìš”.\n",
    "1-2. (ì—°êµ¬ ë³´ê³ ì„œ í•„ìˆ˜ ì¡°ê±´)\n",
    "- Pre-trained ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œ ì–»ëŠ” ì´ì (ë¹ ë¥¸ ìˆ˜ë ´, ì ì€ ë°ì´í„° ìš”êµ¬ëŸ‰ ë“±)\n",
    "- í•™ìŠµ ì „í›„ ì„±ëŠ¥ ë¹„êµí‘œ ë° ì‹œê°í™”\n",
    "- ResNet êµ¬ì¡°ì  íŠ¹ì§•(Residual Block)ì´ ì„±ëŠ¥ì— ê¸°ì—¬í•˜ëŠ” ë°©ì‹ ì„¤ëª…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10639646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "50000\n",
      "Files already downloaded and verified\n",
      "ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1, 4, 9, 5, 0, 2, 9, 5, 0, 9, 6, 9, 2, 1, 2, 0, 6, 2, 6, 4, 6, 4, 8, 8,\n",
      "        1, 7, 1, 5, 1, 7, 8, 2, 3, 0, 1, 8, 6, 2, 9, 7, 5, 3, 6, 1, 5, 3, 2, 1,\n",
      "        3, 0, 4, 6, 0, 6, 5, 8, 2, 2, 0, 1, 3, 5, 8, 3])\n",
      "64\n",
      "ì†ì‹¤ : 2.5255119800567627, ì •í™•ë„ : 0.078125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loader, test_loader = get_CIFAR10_data_loader(ratio=0.1)\n",
    "model = get_custom_resnet50(class_count=10)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(\n",
    "#     model.parameters(),\n",
    "#     lr=1e-3,\n",
    "#     weight_decay=1e-4  # ì •ê·œí™”\n",
    "# )\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "no_train = [test_model(model, loss_function, test_loader, device)] * 5\n",
    "train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "losses = [(\"no_train\", list(map(lambda t:t[0], no_train))), (\"train\", list(map(lambda t:t[0], train)))]\n",
    "accrucies = [(\"no_train\", list(map(lambda t:t[1], no_train))), (\"train\", list(map(lambda t:t[1], train)))]\n",
    "make_loss_accuracy_graph(losses=losses ,accrucies=accrucies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1165a3c",
   "metadata": {},
   "source": [
    "2.ì´ë¯¸ì§€ ë°ì´í„°ì…‹(ì˜ˆ: CIFAR-10, ê°„ë‹¨í•œ custom dataset)ê³¼ ì‚¬ì „ í›ˆë ¨ëœ VGG16 ëª¨ë¸ì„ ê°€ì ¸ì™€ ì „ì´ í•™ìŠµì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n",
    "2-1. Feature Extraction ë‹¨ê³„ë§Œ ì‚¬ìš©í•œ ê²½ìš°ì™€, Fine Tuningì„ ì ìš©í•œ ê²½ìš°ë¥¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¶„ì„í•˜ì„¸ìš”.\n",
    "2-2. (ì—°êµ¬ ë³´ê³ ì„œ í•„ìˆ˜ ì¡°ê±´)\n",
    "- ë‘ ì‹¤í—˜ì˜ ì„±ëŠ¥ ë¹„êµí‘œì™€ í•™ìŠµ ê³¡ì„ (ì†ì‹¤, ì •í™•ë„)\n",
    "- Feature Extractionê³¼ Fine Tuningì˜ ì°¨ì´ ë¶„ì„\n",
    "- Fine Tuning ì‹œ ë ˆì´ì–´ë¥¼ ì–¼ë§ˆë‚˜ ë™ê²°/í•´ì œí–ˆëŠ”ì§€ì™€ ê·¸ ì´ìœ  ì„¤ëª…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# í•™ìŠµë°ì´í„° ìƒì„±\n",
    "train_loader, test_loader = get_CIFAR10_data_loader(ratio=0.1)\n",
    "\n",
    "\n",
    "##################### í’€-íŒŒì¸íŠœë‹ ######################\n",
    "model = get_custom_vgg16(class_count=10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "full_tuning_train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "#####################################################\n",
    "\n",
    "\n",
    "##################### íŠ¹ì§•ì¶”ì¶œ ######################\n",
    "model = get_custom_vgg16(class_count=10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# features ì „ì²´ ë™ê²°\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "feature_extraction_train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "#####################################################\n",
    "\n",
    "# íŒŒì¸íŠœë‹-íŠ¹ì§•ì¶”ì¶œ ë¹„êµ ê·¸ë˜í”„ ìƒì„±\n",
    "losses = [(\"full_tuning\", list(map(lambda t:t[0], full_tuning_train))), (\"feature_extraction\", list(map(lambda t:t[0], feature_extraction_train)))]\n",
    "accrucies = [(\"full_tuning\", list(map(lambda t:t[1], full_tuning_train))), (\"feature_extraction\", list(map(lambda t:t[1], feature_extraction_train)))]\n",
    "make_loss_accuracy_graph(losses=losses ,accrucies=accrucies)\n",
    "\n",
    "\n",
    "\n",
    "# ê° ë ˆì´ì–´ë¥¼ í•˜ë‚˜ì”© ë™ê²°í•´ì œ í•˜ë©´ì„œ íŒŒì¸íŠœë‹ ì„±ëŠ¥ë¹„êµ\n",
    "\n",
    "# Block 1 & 2: [0] ~ [9]\n",
    "\n",
    "# Block 3: [10] ~ [16]\n",
    "\n",
    "# Block 4: [17] ~ [23]\n",
    "\n",
    "# Block 5: [24] ~ [30]\n",
    "\n",
    "##################### Block 1,2 ë™ê²° ######################\n",
    "model = get_custom_vgg16(class_count=10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# features ì „ì²´ ë™ê²°\n",
    "for i, module in enumerate(model.features):\n",
    "    if i <= 9:  # Block 1,2 ë™ê²°\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "partial_345_train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "#####################################################\n",
    "\n",
    "##################### Block 1,2,3 ë™ê²° ######################\n",
    "model = get_custom_vgg16(class_count=10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# features ì „ì²´ ë™ê²°\n",
    "for i, module in enumerate(model.features):\n",
    "    if i <= 16:  # Block 1,2,3 ë™ê²°\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "partial_45_train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "#####################################################\n",
    "\n",
    "##################### Block 1,2,3,4 ë™ê²° ######################\n",
    "model = get_custom_vgg16(class_count=10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# features ì „ì²´ ë™ê²°\n",
    "for i, module in enumerate(model.features):\n",
    "    if i <= 23:  # Block 1,2,3,4 ë™ê²°\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "partial_5_train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "#####################################################\n",
    "\n",
    "# íŒŒì¸íŠœë‹-íŠ¹ì§•ì¶”ì¶œ ë¹„êµ ê·¸ë˜í”„ ìƒì„±\n",
    "losses = [\n",
    "          (\"full_tuning\", list(map(lambda t:t[0], full_tuning_train))),\n",
    "          (\"partial_345\", list(map(lambda t:t[0], partial_345_train))),\n",
    "          (\"partial_45\", list(map(lambda t:t[0], partial_45_train))),\n",
    "          (\"partial_5\", list(map(lambda t:t[0], partial_5_train)))\n",
    "         ]\n",
    "accrucies = [\n",
    "          (\"full_tuning\", list(map(lambda t:t[1], full_tuning_train))),\n",
    "          (\"partial_345\", list(map(lambda t:t[1], partial_345_train))),\n",
    "          (\"partial_45\", list(map(lambda t:t[1], partial_45_train))),\n",
    "          (\"partial_5\", list(map(lambda t:t[1], partial_5_train)))\n",
    "         ]\n",
    "make_loss_accuracy_graph(losses=losses ,accrucies=accrucies)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e6f4e",
   "metadata": {},
   "source": [
    "3. ë™ì¼í•œ ë°ì´í„°ì…‹ì—ì„œ ResNetê³¼ VGG16ì„ ê°ê° í•™ìŠµì‹œì¼œ ì„±ëŠ¥ì„ ë¹„êµí•˜ì„¸ìš”.\n",
    "3-1. ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜, í•™ìŠµ ì†ë„, ìµœì¢… ì„±ëŠ¥(ì •í™•ë„, F1-score ë“±)ì„ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ë¹„êµ ë¶„ì„í•˜ì„¸ìš”.\n",
    "3-2. (ì—°êµ¬ ë³´ê³ ì„œ í•„ìˆ˜ ì¡°ê±´)\n",
    "- ëª¨ë¸ë³„ êµ¬ì¡° ì°¨ì´(Residual vs ë‹¨ìˆœ Conv stack)\n",
    "- í•™ìŠµ ê³¡ì„ ê³¼ ìµœì¢… ì„±ëŠ¥ ì§€í‘œ ë¹„êµ\n",
    "- ì–´ë–¤ ìƒí™©ì—ì„œ ResNet, VGG16 ê°ê°ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ í•©ë¦¬ì ì¸ì§€ í•´ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7907b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loader, test_loader = get_CIFAR10_data_loader(ratio=1.0)\n",
    "\n",
    "##################### VGG16í•™ìŠµ ######################\n",
    "model = get_custom_vgg16(class_count=10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vgg16_train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "#####################################################\n",
    "\n",
    "##################### resnet50í•™ìŠµ ######################\n",
    "model = get_custom_resnet50(class_count=10)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet50_train = train_model(model, optimizer, loss_function, train_loader, test_loader, device)\n",
    "#####################################################\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "losses = [(\"vgg16_train\", list(map(lambda t:t[0], vgg16_train))), (\"resnet50_train\", list(map(lambda t:t[0], resnet50_train)))]\n",
    "accrucies = [(\"vgg16_train\", list(map(lambda t:t[1], vgg16_train))), (\"resnet50_train\", list(map(lambda t:t[1], resnet50_train)))]\n",
    "make_loss_accuracy_graph(losses=losses ,accrucies=accrucies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663777ac",
   "metadata": {},
   "source": [
    "4. ê°€ìƒ ë°ì´í„°ì…‹ ë˜ëŠ” ì†Œê·œëª¨ ì‹¤ì œ ë°ì´í„°ì…‹ì„ ìƒì„±í•œ ë’¤, GridSearchì™€ RandomSearch ê¸°ë²•ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì§„í–‰í•˜ì„¸ìš”.\n",
    "4-1. í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì€ë‹‰ì¸µ í¬ê¸° ë“±ì˜ ì¡°í•©ì„ ì‹¤í—˜í•˜ê³  ìµœì  ì¡°í•©ì„ ì°¾ìœ¼ì„¸ìš”.\n",
    "4-2. (ì—°êµ¬ ë³´ê³ ì„œ í•„ìˆ˜ ì¡°ê±´)\n",
    "- ê° íƒìƒ‰ ë°©ì‹ì˜ ì‹œë„ íšŸìˆ˜ì™€ ê±¸ë¦° ì‹œê°„ ë¹„êµ\n",
    "- ìµœì  ì¡°í•©ê³¼ ê·¸ ì„±ëŠ¥ ê¸°ë¡\n",
    "- GridSearchì™€ RandomSearchê°€ ê°€ì§„ í•œê³„ì™€ í™œìš© ìƒí™© ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_moons_dataset(n_samples:int, noise:float, test_ratio:float)->tuple[torch.tensor, torch.tensor, torch.tensor, torch.tensor]:\n",
    "  \"\"\"\n",
    "  moonsë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "  Args:\n",
    "      ratio: ì „ì²´ ë°ì´í„°ì…‹ ëŒ€ë¹„ ë¹„ì¤‘\n",
    "\n",
    "  Returns:\n",
    "      (X_train, y_train, X_test, y_test)\n",
    "  \"\"\"\n",
    "\n",
    "  X, y = make_moons(n_samples=n_samples, noise=noise, random_state=42)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(\n",
    "      X, y,\n",
    "      test_size=test_ratio,\n",
    "      random_state=42\n",
    "  )\n",
    "\n",
    "  X_train = torch.tensor(X, dtype=torch.float32)\n",
    "  y_train = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "  X_test = torch.tensor(X, dtype=torch.float32)\n",
    "  y_test = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "  return X_train, y_train, X_test, y_test\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        MLPëª¨ë¸ ìƒì„±ì\n",
    "\n",
    "        Args:\n",
    "            input_size : ì…ë ¥ì¸µì˜ ë…¸ë“œ ê°œìˆ˜\n",
    "            hidden_size : ì€ë‹‰ì¸µì˜ ë…¸ë“œ ê°œìˆ˜\n",
    "            output_size : ì¶œë ¥ì¸µì˜ ë…¸ë“œ ê°œìˆ˜\n",
    "\n",
    "        Returns:\n",
    "            (train_loader, test_loader)\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # ì…ë ¥ -> ì€ë‹‰ì¸µ1\n",
    "        self.hidden_layer1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # ì€ë‹‰ì¸µ1 -> ì€ë‹‰ì¸µ2\n",
    "        self.hidden_layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        # ì€ë‹‰ì¸µ2 -> ì¶œë ¥ì¸µ\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # ì€ë‹‰ì¸µì˜ í™œì„±í™” í•¨ìˆ˜\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"ìˆœì „íŒŒ (Forward Propagation)\"\"\"\n",
    "        # 1. ì…ë ¥ -> ì€ë‹‰ì¸µ1\n",
    "        z1 = self.hidden_layer1(x)\n",
    "        a1 = self.activation(z1) # í™œì„±í™”í•¨ìˆ˜ ì ìš©\n",
    "\n",
    "        # 2. ì€ë‹‰ì¸µ1 -> ì€ë‹‰ì¸µ2\n",
    "        z2 = self.hidden_layer2(a1)\n",
    "        a2 = self.activation(z2) # í™œì„±í™”í•¨ìˆ˜ ì ìš©\n",
    "\n",
    "        # 3. ì€ë‹‰ì¸µ2 -> ì¶œë ¥ì¸µ\n",
    "        z3 = self.output_layer(a2)\n",
    "      #  a3 = self.output_activation(z3)\n",
    "        return z3\n",
    "\n",
    "def train_model(epoch:int, model, optimizer, loss_function, device):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ì„ í›ˆë ¨ í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        model : í…ŒìŠ¤íŠ¸ ëª¨ë¸,\n",
    "        optimizer : ì˜µí‹°ë§ˆì´ì €,\n",
    "        loss_function : ì†ì‹¤í•¨ìˆ˜,\n",
    "        device : í›ˆë ¨ì„ ìˆ˜í–‰í•  ë””ë°”ì´ìŠ¤\n",
    "\n",
    "    Returns:\n",
    "        list : ê° ì—í¬í¬ë§ˆë‹¤ í•™ìŠµ ì˜¤ì°¨ìœ¨, ì •í™•ë„(%)\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    X_train, y_train, X_test, y_test = make_moons_dataset(n_samples=1000, noise=0.3, test_ratio=0.3)\n",
    "\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    print(\"Starting Training...\")\n",
    "    result = []\n",
    "    for epoch in range(epoch):\n",
    "      model.train()\n",
    "\n",
    "      predictions = model(X_train)\n",
    "\n",
    "      # ì†ì‹¤(ì˜¤ì°¨) ê³„ì‚°\n",
    "      loss = loss_function(predictions, y_train)\n",
    "\n",
    "      #  ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
    "      loss.backward()\n",
    "\n",
    "      # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "      #  ê·¸ë˜ë””ì–¸íŠ¸ë¡œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "      optimizer.step()\n",
    "\n",
    "      # ì—í¬í¬ ì¢…ë£Œ í›„ ëª¨ë¸ í‰ê°€\n",
    "      model.eval()\n",
    "      with torch.no_grad(): # .no_grad()ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™” (í‰ê°€ ì‹œì—ëŠ” í•„ìš” ì—†ìŒ)\n",
    "          final_predictions = model(X_test)\n",
    "\n",
    "          # ì†ì‹¤ê³„ì‚°\n",
    "          test_loss = loss_function(final_predictions, y_test).item()\n",
    "\n",
    "          # ì •í™•ë„ ê³„ì‚°\n",
    "          rounded_predictions = (final_predictions > 0.5).int()\n",
    "          test_accuracy = (rounded_predictions == y_test).float().mean()\n",
    "          test_accuracy = f\"{test_accuracy.item() * 100:.2f}\"\n",
    "\n",
    "          result.append((test_loss, test_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def make_search_graph(result: dict):\n",
    "    \"\"\"\n",
    "    ì†ì‹¤, ì •í™•ë„ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ì£¼ëŠ” í•¨ìˆ˜ (Scatter Plot)\n",
    "\n",
    "    Args:\n",
    "        result (dict): {í›ˆë ¨ ì‹ë³„ì(str ë˜ëŠ” int): (ì†ì‹¤, ì •í™•ë„) íŠœí”Œ} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬\n",
    "                       ì˜ˆ: {'Trial 1': (0.5, 0.8), 'Trial 2': (0.3, 0.9)}\n",
    "    Returns:\n",
    "        ì—†ìŒ\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 7))\n",
    "\n",
    "    # 1. ì‚°ì ë„ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ 'ê°’' (Value)ì—ì„œ ì¶”ì¶œ\n",
    "    # result.values()ëŠ” [(loss1, acc1), (loss2, acc2), ...] í˜•íƒœ\n",
    "    losses = list(map(lambda t: t[0], result.values()))\n",
    "    accuracies = list(map(lambda t: t[1], result.values()))\n",
    "\n",
    "    # 2. ì‚°ì ë„ ê·¸ë¦¬ê¸°\n",
    "    axes.scatter(losses, accuracies,\n",
    "                 color='blue',\n",
    "                 marker='o',\n",
    "                 s=50,\n",
    "                 alpha=0.7,\n",
    "                 label='Trial Point') # ë²”ë¡€ë¥¼ ìœ„í•´ label ì¶”ê°€\n",
    "\n",
    "    i = 5\n",
    "    for trial_name, (loss, acc) in result.items():\n",
    "\n",
    "        # plt.annotate(ì£¼ì„ í…ìŠ¤íŠ¸, (xì¢Œí‘œ, yì¢Œí‘œ))\n",
    "        axes.annotate(\n",
    "            trial_name,            # ì£¼ì„ í…ìŠ¤íŠ¸: í›ˆë ¨ ì´ë¦„/ì‹ë³„ì (Key)\n",
    "            (loss, acc),           # ì£¼ì„ì´ ë¶™ì„ (X, Y) ì¢Œí‘œ: Value íŠœí”Œ\n",
    "            textcoords=\"offset points\",\n",
    "            #xytext=(5, 5),          # (5, 5) í”½ì…€ë§Œí¼ ì˜¤ë¥¸ìª½ ìœ„ë¡œ ì´ë™\n",
    "            ha='left',              # í…ìŠ¤íŠ¸ì˜ ìˆ˜í‰ ì •ë ¬\n",
    "            fontsize=10,            # í°íŠ¸ í¬ê¸° ì¡°ì •\n",
    "            fontweight='bold',\n",
    "            xytext=(float(loss) + 1+(i/5), float(acc) + 10+i),  # ì£¼ì„ì„ ë°ì´í„°ì™€ ë–¨ì–´ì§„ ì¢Œí‘œì— ìœ„ì¹˜\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=0.5, headwidth=4),\n",
    "        )\n",
    "        i+=5\n",
    "\n",
    "    # 4. ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°\n",
    "    axes.set_title(\"Hyperparameter Search Graph (Loss vs. Accuracy)\")\n",
    "    axes.set_xlabel(\"Loss\")\n",
    "    axes.set_ylabel(\"Accuracy\")\n",
    "    axes.grid(True, linestyle='--', alpha=0.6)\n",
    "    axes.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import product # Grid Searchë¥¼ ìœ„í•œ ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# GridSearchì™€ RandomSearch ê¸°ë²•ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "# í•™ìŠµë¥ , ì—í¬í¬ ìˆ˜, ì€ë‹‰ì¸µ í¬ê¸°\n",
    "\n",
    "# í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.001],\n",
    "    'epoch': [32, 128],\n",
    "    'num_units': [64, 128]\n",
    "}\n",
    "\n",
    "########### GridSearchê¸°ë²•ìœ¼ë¡œ í•™ìŠµ\n",
    "# ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "keys = param_grid.keys()\n",
    "combinations = list(product(*param_grid.values()))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_result = {}\n",
    "for combination in combinations :\n",
    "  lr, epoch, num_units = combination\n",
    "  model = MLP(2, num_units, 1)\n",
    "\n",
    "  loss_function = nn.BCEWithLogitsLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  result = train_model(epoch=epoch, model=model, optimizer=optimizer, loss_function=loss_function, device=device)\n",
    "\n",
    "  grid_result[f\"lr: {lr}, epoch: {epoch}, num_units: {num_units}\"] = result[-1]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"ì´ ì‹¤í–‰ ì‹œê°„: {execution_time:.6f}ì´ˆ\")\n",
    "print(grid_result)\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "make_search_graph(grid_result)\n",
    "\n",
    "\n",
    "########### RandomSearchê¸°ë²•ìœ¼ë¡œ í•™ìŠµ\n",
    "\n",
    "def sample_hyperparameters(param_space):\n",
    "    \"\"\"ì •ì˜ëœ ê³µê°„ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.\"\"\"\n",
    "    sampled_params = []\n",
    "\n",
    "    for name, spec in param_grid.items():\n",
    "        low = spec[0]\n",
    "        high = spec[1]\n",
    "        sampled_params.append(random.uniform(low, high))\n",
    "\n",
    "    return sampled_params\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "random_result = {}\n",
    "for i in range(8):\n",
    "    # 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¬´ì‘ìœ„ ìƒ˜í”Œë§\n",
    "    current_params = sample_hyperparameters(param_grid)\n",
    "    lr, epoch, num_units = current_params\n",
    "    model = MLP(2, int(num_units), 1)\n",
    "\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    result = train_model(epoch=int(epoch), model=model, optimizer=optimizer, loss_function=loss_function, device=device)\n",
    "\n",
    "    random_result[f\"lr: {lr}, epoch: {int(epoch)}, num_units: {int(num_units)}\"] = result[-1]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"ì´ ì‹¤í–‰ ì‹œê°„: {execution_time:.6f}ì´ˆ\")\n",
    "\n",
    "print(grid_result)\n",
    "print(random_result)\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "make_search_graph(random_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
